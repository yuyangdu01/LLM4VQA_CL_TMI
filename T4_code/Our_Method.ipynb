{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "46pNxfRKsBpD"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 0,
     "status": "ok",
     "timestamp": 1740666273242,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "SISMZXOwX-OH"
   },
   "outputs": [],
   "source": [
    "T=2\n",
    "N_Balance = 2000\n",
    "DS_weight=0.9\n",
    "DI_weight=0.1\n",
    "hard_label_weight=0.8\n",
    "epoch_num=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23788,
     "status": "ok",
     "timestamp": 1740666297030,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "mjvXse7NV23K",
    "outputId": "2085ba0b-48f6-4e05-ebe5-0b79f3195f86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6475,
     "status": "ok",
     "timestamp": 1740666303506,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "WS66FegVV4_Z",
    "outputId": "377f8a81-c406-4dc4-df23-d34d4ab45aa4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-02bd375b9991>:5: DeprecationWarning: lib2to3 package is deprecated and may not be able to parse Python 3.10+\n",
      "  from lib2to3.pytree import convert\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"/content/drive/MyDrive/Colab Notebooks/research/multi-modality/endovis18\")\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from lib2to3.pytree import convert\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7326,
     "status": "ok",
     "timestamp": 1740666310838,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "0gLMdAW7W6oi",
    "outputId": "e54bb37e-5242-4768-b8d8-15eb8272c3db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==4.18.0\n",
      "  Downloading transformers-4.18.0-py3-none-any.whl.metadata (70 kB)\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/70.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.3/70.3 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.18.0) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.18.0) (0.28.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.18.0) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.18.0) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.18.0) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.18.0) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.18.0) (2.32.3)\n",
      "Collecting sacremoses (from transformers==4.18.0)\n",
      "  Downloading sacremoses-0.1.1-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1 (from transformers==4.18.0)\n",
      "  Downloading tokenizers-0.12.1.tar.gz (220 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.7/220.7 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.18.0) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.18.0) (2024.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.18.0) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.18.0) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.18.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.18.0) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.18.0) (2025.1.31)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from sacremoses->transformers==4.18.0) (8.1.8)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from sacremoses->transformers==4.18.0) (1.4.2)\n",
      "Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: tokenizers\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for tokenizers \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m See above for output.\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  Building wheel for tokenizers (pyproject.toml) ... \u001b[?25l\u001b[?25herror\n",
      "\u001b[31m  ERROR: Failed building wheel for tokenizers\u001b[0m\u001b[31m\n",
      "\u001b[0mFailed to build tokenizers\n",
      "\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (tokenizers)\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "pip install transformers==4.18.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 16396,
     "status": "ok",
     "timestamp": 1740666327236,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "npAwHewjXC-5"
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "from torch.utils.data  import DataLoader\n",
    "import sys\n",
    "sys.path.append('/content/drive/MyDrive/Colab Notebooks/research/multi-modality/endovis18/Surgical_VQA')\n",
    "from utils import *\n",
    "from dataloaders.dataloaderClassification import *\n",
    "from models.VisualBertClassification import VisualBertClassification\n",
    "from models.VisualBertResMLPClassification import VisualBertResMLPClassification\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1740666327238,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "7mVVTF5OZNZS"
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed=27):\n",
    "    '''\n",
    "    Set random seed for reproducible experiments\n",
    "    Inputs: seed number\n",
    "    '''\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 0,
     "status": "ok",
     "timestamp": 1740666327239,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "LSmyDMWNZg4a"
   },
   "outputs": [],
   "source": [
    "# training function for our CL algorithm\n",
    "def train_d4(args, train_dataloader, model, criterion, optimizer, epoch, tokenizer, device):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    label_true = None\n",
    "    label_pred = None\n",
    "    label_score = None\n",
    "\n",
    "\n",
    "    for i, (_, visual_features, q, labels, t5_loss) in enumerate(train_dataloader,0):\n",
    "\n",
    "        label_number = labels.numpy()[0]\n",
    "\n",
    "        # prepare questions\n",
    "        questions = []\n",
    "        for question in q: questions.append(question)\n",
    "        inputs = tokenizer(questions, return_tensors=\"pt\", padding=\"max_length\", max_length=args.question_len)\n",
    "\n",
    "        # t5 loss\n",
    "        t5_loss_list = []\n",
    "        for j in range(len(t5_loss)):\n",
    "          #tmp = str2list(t5_loss[j])\n",
    "          tmp = t5_loss[j][:22]\n",
    "          t5_loss_list.append(tmp)\n",
    "        check = np.reciprocal(t5_loss_list)\n",
    "        t5_loss_tensor = torch.tensor(check)\n",
    "\n",
    "        t5_loss_tensor = t5_loss_tensor.to(device)\n",
    "\n",
    "        # GPU / CPU\n",
    "        visual_features = visual_features.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        #print(labels)\n",
    "\n",
    "        outputs = model(inputs, visual_features)\n",
    "\n",
    "        soft_target_17 = model_17(inputs, visual_features)\n",
    "        soft_target_18 = model_18(inputs, visual_features)\n",
    "        soft_target = model_old(inputs, visual_features)\n",
    "\n",
    "\n",
    "        loss1 = criterion(outputs, labels)\n",
    "\n",
    "        outputs_S = F.softmax(outputs[:,:out_features]/T,dim=1)\n",
    "\n",
    "        outputs_T_17 = F.softmax(soft_target_17[:,:out_features]/T,dim=1)\n",
    "        outputs_T_18 = F.softmax(soft_target_18[:,:out_features]/T,dim=1)\n",
    "        outputs_T = F.softmax(soft_target[:,:out_features]/T,dim=1)\n",
    "\n",
    "        outputs_t5_loss = F.softmax(t5_loss_tensor[:,:out_features]/T,dim=1)\n",
    "\n",
    "        loss2_17 = outputs_T_17.mul(-1*torch.log(outputs_S))\n",
    "        loss2_17 = loss2_17.sum(1)\n",
    "        loss2_17 = loss2_17.mean()*T*T\n",
    "\n",
    "        loss2_18 = outputs_T_18.mul(-1*torch.log(outputs_S))\n",
    "        loss2_18 = loss2_18.sum(1)\n",
    "        loss2_18 = loss2_18.mean()*T*T\n",
    "\n",
    "        loss2 = outputs_T.mul(-1*torch.log(outputs_S))\n",
    "        loss2 = loss2.sum(1)\n",
    "        loss2 = loss2.mean()*T*T\n",
    "\n",
    "        loss3 = outputs_t5_loss.mul(-1*torch.log(outputs_S))\n",
    "        loss3 = loss3.sum(1)\n",
    "        loss3 = loss3.mean()*T*T\n",
    "\n",
    "        #loss = loss1 * 0.8 + loss2 * 0.123 + loss3 * 0.077\n",
    "        #loss = loss1 * acc_weight.at[label_number,'weight_true_label'] + loss2_17 * (acc_weight.at[label_number,'weight_soft'])*0.05 + loss2_18 * (acc_weight.at[label_number,'weight_soft'])*0.05 + loss2 * (acc_weight.at[label_number,'weight_soft'])*0.9 + loss3 * acc_weight.at[label_number,'weight_llm']\n",
    "\n",
    "        loss = loss1 * acc_weight.at[label_number,'weight_true_label'] + loss2_17 * (acc_weight.at[label_number,'weight_soft'])/3 + loss2_18 * (acc_weight.at[label_number,'weight_soft'])/3 + loss2 * (acc_weight.at[label_number,'weight_soft'])/3 + loss3 * acc_weight.at[label_number,'weight_llm']\n",
    "\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        scores, predicted = torch.max(F.softmax(outputs, dim=1).data, 1)\n",
    "\n",
    "        #print(predicted)\n",
    "\n",
    "        label_true = labels.data.cpu() if label_true == None else torch.cat((label_true, labels.data.cpu()), 0)\n",
    "        label_pred = predicted.data.cpu() if label_pred == None else torch.cat((label_pred, predicted.data.cpu()), 0)\n",
    "        label_score = scores.data.cpu() if label_score == None else torch.cat((label_score, scores.data.cpu()), 0)\n",
    "\n",
    "    # loss and acc\n",
    "    acc, c_acc = calc_acc(label_true, label_pred), calc_classwise_acc(label_true, label_pred)\n",
    "    precision, recall, fscore = calc_precision_recall_fscore(label_true, label_pred)\n",
    "    print('Train: epoch: %d loss: %.6f | Acc: %.6f | Precision: %.6f | Recall: %.6f | FScore: %.6f' %(epoch, total_loss, acc, precision, recall, fscore))\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1740666327240,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "35lhtZgoZdnW"
   },
   "outputs": [],
   "source": [
    "def validate_17(args, val_loader, model, criterion, epoch, tokenizer, device, save_output = False):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    label_true = None\n",
    "    label_pred = None\n",
    "    label_score = None\n",
    "    file_names = list()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    convert_arr = ['kidney', 'Idle', 'Grasping', 'Retraction', 'Tissue_Manipulation',\n",
    "              'Tool_Manipulation', 'Cutting', 'Cauterization', 'Suction',\n",
    "               'Looping', 'Suturing', 'Clipping', 'Staple', 'Ultrasound_Sensing',\n",
    "              'left-top', 'right-top', 'left-bottom', 'right-bottom',\n",
    "                   'no', 'yes','left', 'right']\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (file_name, visual_features, q, labels) in enumerate(val_loader,0):\n",
    "            # prepare questions\n",
    "            questions = []\n",
    "            for question in q: questions.append(question)\n",
    "            inputs = tokenizer(questions, return_tensors=\"pt\", padding=\"max_length\", max_length=args.question_len)\n",
    "\n",
    "            # GPU / CPU\n",
    "            visual_features = visual_features.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs, visual_features)\n",
    "\n",
    "            #print(labels)\n",
    "\n",
    "            loss = criterion(outputs,labels)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            scores, predicted = torch.max(F.softmax(outputs, dim=1).data, 1)\n",
    "\n",
    "            #print(predicted)\n",
    "\n",
    "            label_true = labels.data.cpu() if label_true == None else torch.cat((label_true, labels.data.cpu()), 0)\n",
    "            label_pred = predicted.data.cpu() if label_pred == None else torch.cat((label_pred, predicted.data.cpu()), 0)\n",
    "            label_score = scores.data.cpu() if label_score == None else torch.cat((label_score, scores.data.cpu()), 0)\n",
    "            for f in file_name: file_names.append(f)\n",
    "\n",
    "    acc = calc_acc(label_true, label_pred)\n",
    "    c_acc = 0.0\n",
    "    # c_acc = calc_classwise_acc(label_true, label_pred)\n",
    "    precision, recall, fscore = calc_precision_recall_fscore(label_true, label_pred)\n",
    "\n",
    "    print('Test: epoch: %d loss: %.6f | Acc: %.6f | Precision: %.6f | Recall: %.6f | FScore: %.6f' %(epoch, total_loss, acc, precision, recall, fscore))\n",
    "\n",
    "    if save_output:\n",
    "        '''\n",
    "            Saving predictions\n",
    "        '''\n",
    "        if os.path.exists(args.checkpoint_dir + 'text_files') == False:\n",
    "            os.mkdir(args.checkpoint_dir + 'text_files' )\n",
    "        file1 = open(args.checkpoint_dir + 'text_files/labels.txt', 'w')\n",
    "        file1.write(str(label_true))\n",
    "        file1.close()\n",
    "\n",
    "        file1 = open(args.checkpoint_dir + 'text_files/predictions.txt', 'w')\n",
    "        file1.write(str(label_pred))\n",
    "        file1.close()\n",
    "\n",
    "        if args.dataset_type == 'med_vqa':\n",
    "            if args.dataset_cat == 'cat1':\n",
    "                convert_arr = ['cta - ct angiography', 'no', 'us - ultrasound', 'xr - plain film', 'noncontrast', 'yes', 't2', 'ct w/contrast (iv)', 'mr - flair', 'mammograph', 'ct with iv contrast',\n",
    "                            'gi and iv', 't1', 'mr - t2 weighted', 'mr - t1w w/gadolinium', 'contrast', 'iv', 'an - angiogram', 'mra - mr angiography/venography', 'nm - nuclear medicine', 'mr - dwi diffusion weighted',\n",
    "                            'ct - gi & iv contrast', 'ct noncontrast', 'mr - other pulse seq.', 'ct with gi and iv contrast', 'flair', 'mr - t1w w/gd (fat suppressed)', 'ugi - upper gi', 'mr - adc map (app diff coeff)',\n",
    "                            'bas - barium swallow', 'pet - positron emission', 'mr - pdw proton density', 'mr - t1w - noncontrast', 'be - barium enema', 'us-d - doppler ultrasound', 'mr - stir', 'mr - flair w/gd',\n",
    "                            'ct with gi contrast', 'venogram', 'mr t2* gradient,gre,mpgr,swan,swi', 'mr - fiesta', 'ct - myelogram', 'gi', 'sbft - small bowel', 'pet-ct fusion']\n",
    "            elif args.dataset_cat == 'cat2':\n",
    "                convert_arr = ['axial', 'longitudinal', 'coronal', 'lateral', 'ap', 'sagittal', 'mammo - mlo', 'pa', 'mammo - cc', 'transverse', 'mammo - mag cc', 'frontal', 'oblique', '3d reconstruction', 'decubitus', 'mammo - xcc']\n",
    "            else:\n",
    "                convert_arr = ['lung, mediastinum, pleura', 'skull and contents', 'genitourinary', 'spine and contents', 'musculoskeletal', 'heart and great vessels', 'vascular and lymphatic', 'gastrointestinal', 'face, sinuses, and neck', 'breast']\n",
    "        elif args.dataset_type == 'c80':\n",
    "            convert_arr = ['no', 'calot triangle dissection', 'yes', '1', '2', 'gallbladder dissection',\n",
    "                            'clipping cutting', 'gallbladder retraction', '0', 'cleaning coagulation',\n",
    "                            'gallbladder packaging', 'preparation', '3']\n",
    "        elif args.dataset_type == 'm18':\n",
    "            convert_arr = ['kidney', 'Idle', 'Grasping', 'Retraction', 'Tissue_Manipulation',\n",
    "                            'Tool_Manipulation', 'Cutting', 'Cauterization', 'Suction',\n",
    "                            'Looping', 'Suturing', 'Clipping', 'Staple', 'Ultrasound_Sensing',\n",
    "                            'left-top', 'right-top', 'left-bottom', 'right-bottom']\n",
    "\n",
    "        df = pd.DataFrame(columns=[\"Img\", \"Ground Truth\", \"Prediction\"])\n",
    "        for i in range(len(label_true)):\n",
    "            df = df.append({'Img': file_names[i], 'Ground Truth': convert_arr[label_true[i]], 'Prediction': convert_arr[label_pred[i]]}, ignore_index=True)\n",
    "\n",
    "        df.to_csv(args.checkpoint_dir + args.checkpoint_dir.split('/')[1] + '_' + args.checkpoint_dir.split('/')[2] + '_eval.csv')\n",
    "\n",
    "    return (acc, c_acc, precision, recall, fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1740666327254,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "iO22hFlWZs7g"
   },
   "outputs": [],
   "source": [
    "def validate_18_d3_d4(args, val_loader, model, criterion, epoch, tokenizer, device, save_output = False):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    label_true = None\n",
    "    label_pred = None\n",
    "    label_score = None\n",
    "    file_names = list()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (file_name, visual_features, q, labels, _) in enumerate(val_loader,0):\n",
    "            # prepare questions\n",
    "            questions = []\n",
    "            for question in q: questions.append(question)\n",
    "            inputs = tokenizer(questions, return_tensors=\"pt\", padding=\"max_length\", max_length=args.question_len)\n",
    "\n",
    "            # GPU / CPU\n",
    "            visual_features = visual_features.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs, visual_features)\n",
    "\n",
    "\n",
    "            loss = criterion(outputs,labels)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            scores, predicted = torch.max(F.softmax(outputs, dim=1).data, 1)\n",
    "\n",
    "\n",
    "            label_true = labels.data.cpu() if label_true == None else torch.cat((label_true, labels.data.cpu()), 0)\n",
    "            label_pred = predicted.data.cpu() if label_pred == None else torch.cat((label_pred, predicted.data.cpu()), 0)\n",
    "            label_score = scores.data.cpu() if label_score == None else torch.cat((label_score, scores.data.cpu()), 0)\n",
    "            for f in file_name: file_names.append(f)\n",
    "\n",
    "    acc = calc_acc(label_true, label_pred)\n",
    "    c_acc = 0.0\n",
    "    # c_acc = calc_classwise_acc(label_true, label_pred)\n",
    "    precision, recall, fscore = calc_precision_recall_fscore(label_true, label_pred)\n",
    "\n",
    "    print('Test: epoch: %d loss: %.6f | Acc: %.6f | Precision: %.6f | Recall: %.6f | FScore: %.6f' %(epoch, total_loss, acc, precision, recall, fscore))\n",
    "\n",
    "    if save_output:\n",
    "        '''\n",
    "            Saving predictions\n",
    "        '''\n",
    "        if os.path.exists(args.checkpoint_dir + 'text_files') == False:\n",
    "            os.mkdir(args.checkpoint_dir + 'text_files' )\n",
    "        file1 = open(args.checkpoint_dir + 'text_files/labels.txt', 'w')\n",
    "        file1.write(str(label_true))\n",
    "        file1.close()\n",
    "\n",
    "        file1 = open(args.checkpoint_dir + 'text_files/predictions.txt', 'w')\n",
    "        file1.write(str(label_pred))\n",
    "        file1.close()\n",
    "\n",
    "        if args.dataset_type == 'med_vqa':\n",
    "            if args.dataset_cat == 'cat1':\n",
    "                convert_arr = ['cta - ct angiography', 'no', 'us - ultrasound', 'xr - plain film', 'noncontrast', 'yes', 't2', 'ct w/contrast (iv)', 'mr - flair', 'mammograph', 'ct with iv contrast',\n",
    "                            'gi and iv', 't1', 'mr - t2 weighted', 'mr - t1w w/gadolinium', 'contrast', 'iv', 'an - angiogram', 'mra - mr angiography/venography', 'nm - nuclear medicine', 'mr - dwi diffusion weighted',\n",
    "                            'ct - gi & iv contrast', 'ct noncontrast', 'mr - other pulse seq.', 'ct with gi and iv contrast', 'flair', 'mr - t1w w/gd (fat suppressed)', 'ugi - upper gi', 'mr - adc map (app diff coeff)',\n",
    "                            'bas - barium swallow', 'pet - positron emission', 'mr - pdw proton density', 'mr - t1w - noncontrast', 'be - barium enema', 'us-d - doppler ultrasound', 'mr - stir', 'mr - flair w/gd',\n",
    "                            'ct with gi contrast', 'venogram', 'mr t2* gradient,gre,mpgr,swan,swi', 'mr - fiesta', 'ct - myelogram', 'gi', 'sbft - small bowel', 'pet-ct fusion']\n",
    "            elif args.dataset_cat == 'cat2':\n",
    "                convert_arr = ['axial', 'longitudinal', 'coronal', 'lateral', 'ap', 'sagittal', 'mammo - mlo', 'pa', 'mammo - cc', 'transverse', 'mammo - mag cc', 'frontal', 'oblique', '3d reconstruction', 'decubitus', 'mammo - xcc']\n",
    "            else:\n",
    "                convert_arr = ['lung, mediastinum, pleura', 'skull and contents', 'genitourinary', 'spine and contents', 'musculoskeletal', 'heart and great vessels', 'vascular and lymphatic', 'gastrointestinal', 'face, sinuses, and neck', 'breast']\n",
    "        elif args.dataset_type == 'c80':\n",
    "            convert_arr = ['no', 'calot triangle dissection', 'yes', '1', '2', 'gallbladder dissection',\n",
    "                            'clipping cutting', 'gallbladder retraction', '0', 'cleaning coagulation',\n",
    "                            'gallbladder packaging', 'preparation', '3']\n",
    "        elif args.dataset_type == 'm18':\n",
    "            convert_arr = ['kidney', 'Idle', 'Grasping', 'Retraction', 'Tissue_Manipulation',\n",
    "                            'Tool_Manipulation', 'Cutting', 'Cauterization', 'Suction',\n",
    "                            'Looping', 'Suturing', 'Clipping', 'Staple', 'Ultrasound_Sensing',\n",
    "                            'left-top', 'right-top', 'left-bottom', 'right-bottom']\n",
    "\n",
    "        df = pd.DataFrame(columns=[\"Img\", \"Ground Truth\", \"Prediction\"])\n",
    "        for i in range(len(label_true)):\n",
    "            df = df.append({'Img': file_names[i], 'Ground Truth': convert_arr[label_true[i]], 'Prediction': convert_arr[label_pred[i]]}, ignore_index=True)\n",
    "\n",
    "        df.to_csv(args.checkpoint_dir + args.checkpoint_dir.split('/')[1] + '_' + args.checkpoint_dir.split('/')[2] + '_eval.csv')\n",
    "\n",
    "    return (acc, c_acc, precision, recall, fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 0,
     "status": "ok",
     "timestamp": 1740666327254,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "2U0-bmYrZwAy"
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='VisualQuestionAnswerClassification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1740666327257,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "jFwtYN9BZ-kq",
    "outputId": "ed5ffce0-d847-44dc-cae3-e16bf13bb27d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--emb_dim'], dest='emb_dim', nargs=None, const=None, default=300, type=<class 'int'>, choices=None, required=False, help='dimension of word embeddings.', metavar=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.add_argument('--emb_dim',     type=int,  default=300, help='dimension of word embeddings.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1740666327258,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "zfkYxKvtZ-Sp",
    "outputId": "23dd9198-e327-4047-d9f0-99cd46441c8e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--encoder_layers'], dest='encoder_layers', nargs=None, const=None, default=6, type=<class 'int'>, choices=None, required=False, help='the number of layers of encoder in Transformer.', metavar=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.add_argument('--n_heads',     type=int,  default=8,  help='Multi-head attention.')\n",
    "parser.add_argument('--dropout',     type=float, default=0.1, help='dropout')\n",
    "parser.add_argument('--encoder_layers',  type=int,  default=6,  help='the number of layers of encoder in Transformer.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1740666327264,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "7FAcRqTwaaO3",
    "outputId": "ae8f2017-ad03-41e8-acfd-b6e3a96313ed"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--validate'], dest='validate', nargs=None, const=None, default=False, type=None, choices=None, required=False, help='When only validation required False/True', metavar=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training parameters\n",
    "parser.add_argument('--epochs',       type=int,   default=80,     help='number of epochs to train for (if early stopping is not triggered).') #80, 26\n",
    "parser.add_argument('--batch_size',     type=int,   default=64,      help='batch_size')\n",
    "parser.add_argument('--workers',      type=int,   default=1,     help='for data-loading; right now, only 1 works with h5pys.')\n",
    "parser.add_argument('--print_freq',     type=int,   default=100,     help='print training/validation stats every __ batches.')\n",
    "\n",
    "# existing checkpoint\n",
    "parser.add_argument('--checkpoint',     default=None,             help='path to checkpoint, None if none.')\n",
    "\n",
    "parser.add_argument('--lr', type=float,  default=0.00001, help='0.000005, 0.00001, 0.000005')\n",
    "parser.add_argument('--checkpoint_dir',   default= '/content/drive/MyDrive/Colab Notebooks/research/multi-modality/endovis18/result/',    help='med_vqa_c$version$/m18/c80//m18_vid$temporal_size$/c80_vid$temporal_size$') #clf_v1_2_1x1/med_vqa_c3\n",
    "parser.add_argument('--dataset_type',    default= 'm18',         help='med_vqa/m18/c80/m18_vid/c80_vid')\n",
    "parser.add_argument('--dataset_cat',    default= 'None',         help='cat1/cat2/cat3')\n",
    "parser.add_argument('--transformer_ver',  default= 'vbrm',         help='vb/vbrm')\n",
    "parser.add_argument('--tokenizer_ver',   default= 'v2',          help='v2/v3')\n",
    "parser.add_argument('--patch_size',     default= 5,           help='1/2/3/4/5')\n",
    "parser.add_argument('--temporal_size',   default= 3,           help='1/2/3/4/5')\n",
    "parser.add_argument('--question_len',    default= 25,          help='25')\n",
    "parser.add_argument('--num_class',     default= 2,           help='25')\n",
    "parser.add_argument('--validate',      default=False,          help='When only validation required False/True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1740666327267,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "d9GEDvXfbS4a",
    "outputId": "f2f2a254-4727-4caa-97b8-f0b562d7a146"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['-f'], dest='f', nargs=None, const=None, default=None, type=None, choices=None, required=False, help=None, metavar=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.add_argument('-f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 0,
     "status": "ok",
     "timestamp": 1740666327267,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "injs_EEEbXEy"
   },
   "outputs": [],
   "source": [
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1740666327274,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "jH_3QP_9bcE0"
   },
   "outputs": [],
   "source": [
    "# load checkpoint, these parameters can't be modified\n",
    "final_args = {\"emb_dim\": 300, \"n_heads\": 8, \"dropout\": 0.1, \"encoder_layers\": 6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1740666327279,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "XYYWg4abbf8U"
   },
   "outputs": [],
   "source": [
    "seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1740666327280,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "baxNHnoabiN2",
    "outputId": "df432691-ba42-4bdf-f367-c6c6d4d7b2af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device = cuda\n"
     ]
    }
   ],
   "source": [
    "# GPU or CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # sets device for model and PyTorch tensors\n",
    "cudnn.benchmark = True  # set to true only if inputs to model are fixed size; otherwise lot of computational overhead\n",
    "print('device =', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1740666327288,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "pHTkp2NSbma-"
   },
   "outputs": [],
   "source": [
    "# best model initialize\n",
    "start_epoch = 1\n",
    "best_epoch = [0]\n",
    "best_results = [0.0]\n",
    "epochs_since_improvement = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 2741,
     "status": "ok",
     "timestamp": 1740666330029,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "R4Zfn7fHboTq"
   },
   "outputs": [],
   "source": [
    "# tokenizer\n",
    "tokenizer = None\n",
    "tokenizer = BertTokenizer.from_pretrained(\"/content/drive/MyDrive/Colab Notebooks/research/multi-modality/endovis18\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1740666330039,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "vjC-eg_YdL7E",
    "outputId": "5346e040-c4e5-4924-fc9c-02b782173580"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizer(name_or_path='/content/drive/MyDrive/Colab Notebooks/research/multi-modality/endovis18', vocab_size=237, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True, added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t2: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t3: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t4: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t237: AddedToken(\"cauterization\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t238: AddedToken(\"left-top\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t239: AddedToken(\"left-bottom\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t240: AddedToken(\"right-top\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t241: AddedToken(\"right-bottom\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t242: AddedToken(\"##?\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t243: AddedToken(\"##,\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "}\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1740666330041,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "M7i8942GdZDy"
   },
   "outputs": [],
   "source": [
    "args.num_class = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 3132,
     "status": "ok",
     "timestamp": 1740666333173,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "l-3t1VlVdcOL"
   },
   "outputs": [],
   "source": [
    "#if args.transformer_ver == 'vb':\n",
    "model = VisualBertClassification(vocab_size=len(tokenizer), layers=6, n_heads=8, num_class = args.num_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1740666333176,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "iLutJbeodgdC"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1740666333177,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "reTeLejRdj24"
   },
   "outputs": [],
   "source": [
    "# 将一个表示浮点数列表的字符串转换为实际的浮点数列表\n",
    "def str2list(target_str):\n",
    "  res=target_str.strip('[')\n",
    "  res=res.strip(']')\n",
    "  res=res.split(',')\n",
    "\n",
    "  for i in range(len(res)):\n",
    "    res[i] = res[i].strip() # 去掉空格\n",
    "\n",
    "  new_list = [float(x) for x in res]\n",
    "  return new_list[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mWMuLIWDdoE_"
   },
   "source": [
    "Imbalance Issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 613,
     "status": "ok",
     "timestamp": 1740666333790,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "6ga6aYE6d1gh",
    "outputId": "31c41e0b-aefd-4736-eac9-74491d623e9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5067637700012111\n"
     ]
    }
   ],
   "source": [
    "# Since the three dataset is already fixed, we pre-store the label distribution in a CSV file to save the time loading all the data\n",
    "# Load all the data will be a VERY time-consuming in Colab\n",
    "import math\n",
    "\n",
    "frequency_all = pd.read_csv(\"frequency_all.csv\")\n",
    "max_17_18_daisi_d4 = frequency_all['17+18+daisi+dataset_4'].max()\n",
    "min_17_18_daisi_d4 = frequency_all['17+18+daisi+dataset_4'].min()\n",
    "IR_17_18_daisi_d4 = max_17_18_daisi_d4 / min_17_18_daisi_d4\n",
    "ln_IR_17_18_daisi_d4 = math.log(IR_17_18_daisi_d4,N_Balance)\n",
    "\n",
    "print(ln_IR_17_18_daisi_d4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a4SZsQEJfHTC"
   },
   "source": [
    "Load dataset_4 and CL model trained on 17,18,DAISI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1740666333792,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "hVDzQ2adfVGD"
   },
   "outputs": [],
   "source": [
    "class LrspDataset(Dataset):\n",
    "    def __init__(self, csv_file, data_type, patch_size=5):\n",
    "        self.patch_size = patch_size\n",
    "        tmp = pd.read_csv(csv_file)\n",
    "        self.data_frame = tmp[tmp['type']==data_type]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data_frame.iloc[idx]\n",
    "        file_name = str(sample['path'])\n",
    "        q = sample['q']\n",
    "        labels = torch.tensor(sample['labels'])\n",
    "\n",
    "        visual_feature_loc = '/' + os.path.join('content/drive/MyDrive/Colab Notebooks/research/multi-modality/dataset_4/vqa/img_features',(str(self.patch_size)+'x'+str(self.patch_size)),file_name+'.hdf5')\n",
    "        frame_data = h5py.File(visual_feature_loc, 'r')\n",
    "        visual_features = torch.from_numpy(frame_data['visual_features'][:])\n",
    "\n",
    "        t5_loss = torch.tensor(eval(sample['t5_loss']))\n",
    "\n",
    "        return file_name, visual_features, q, labels, t5_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5686,
     "status": "ok",
     "timestamp": 1740666339479,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "XzRV36cmfX5i",
    "outputId": "acefa0ff-a928-405d-cdf0-6add756b4b69"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "903"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_lrsp = LrspDataset('/content/drive/MyDrive/Colab Notebooks/research/multi-modality/dataset_4/data.csv','train',patch_size=5)\n",
    "train_dataloader_lrsp = DataLoader(dataset=train_dataset_lrsp, batch_size=1, shuffle=True)\n",
    "len(train_dataset_lrsp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 145396,
     "status": "ok",
     "timestamp": 1740666484876,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "Zm1L0OGAg87a"
   },
   "outputs": [],
   "source": [
    "# old model 17\n",
    "checkpoint_17 = torch.load('/content/drive/MyDrive/Colab Notebooks/research/multi-modality/endovis17/Pretrain_t1.pth.tar')\n",
    "model_17 = checkpoint_17['model']\n",
    "\n",
    "# old model 18\n",
    "checkpoint_18 = torch.load('/content/drive/MyDrive/Colab Notebooks/research/multi-modality/endovis17/Pretrain_t2.pth.tar')\n",
    "model_18 = checkpoint_18['model']\n",
    "\n",
    "# old model daisi\n",
    "checkpoint_old = torch.load('/content/drive/MyDrive/Colab Notebooks/research/multi-modality/daisi_vqa_final/result/4980.pth.tar')\n",
    "model_old = checkpoint_old['model']\n",
    "\n",
    "# new model\n",
    "checkpoint_old = torch.load('/content/drive/MyDrive/Colab Notebooks/research/multi-modality/daisi_vqa_final/result/4980.pth.tar')\n",
    "model = checkpoint_old['model']\n",
    "\n",
    "optimizer = checkpoint_old['optimizer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1740666484879,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "4hgblJpJxxC7"
   },
   "outputs": [],
   "source": [
    "#change the last FC layer for new model (add the node for new classes)\n",
    "num_new_class = 4\n",
    "\n",
    "def kaiming_normal_init(m):\n",
    "\tif isinstance(m, nn.Conv2d):\n",
    "\t\tnn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "\telif isinstance(m, nn.Linear):\n",
    "\t\tnn.init.kaiming_normal_(m.weight, nonlinearity='sigmoid')\n",
    "\n",
    "# Old number of input/output channel of the last FC layer in old model\n",
    "in_features = model_18.classifier.in_features\n",
    "out_features = model_18.classifier.out_features\n",
    "\n",
    "# Old weight/bias of the last FC layer\n",
    "weight = model_18.classifier.weight.data\n",
    "bias = model_18.classifier.bias.data\n",
    "\n",
    "# New number of output channel of the last FC layer in new model\n",
    "new_out_features = num_new_class + out_features\n",
    "\n",
    "# Creat a new FC layer and initial it's weight/bias\n",
    "new_fc = nn.Linear(in_features, new_out_features)\n",
    "kaiming_normal_init(new_fc.weight)\n",
    "new_fc.weight.data[:out_features] = weight\n",
    "new_fc.bias.data[:out_features] = bias\n",
    "\n",
    "# Replace the old FC layer\n",
    "model_17.classifier = new_fc\n",
    "model_18.classifier = new_fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1740666484882,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "P70g_t5Ng8jj"
   },
   "outputs": [],
   "source": [
    "#change the last FC layer for new model (add the node for new classes)\n",
    "num_new_class = 2\n",
    "\n",
    "def kaiming_normal_init(m):\n",
    "\tif isinstance(m, nn.Conv2d):\n",
    "\t\tnn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "\telif isinstance(m, nn.Linear):\n",
    "\t\tnn.init.kaiming_normal_(m.weight, nonlinearity='sigmoid')\n",
    "\n",
    "# Old number of input/output channel of the last FC layer in old model\n",
    "in_features = model_old.classifier.in_features\n",
    "out_features = model_old.classifier.out_features\n",
    "\n",
    "# Old weight/bias of the last FC layer\n",
    "weight = model_old.classifier.weight.data\n",
    "bias = model_old.classifier.bias.data\n",
    "\n",
    "# New number of output channel of the last FC layer in new model\n",
    "new_out_features = num_new_class + out_features\n",
    "\n",
    "# Creat a new FC layer and initial it's weight/bias\n",
    "new_fc = nn.Linear(in_features, new_out_features)\n",
    "kaiming_normal_init(new_fc.weight)\n",
    "new_fc.weight.data[:out_features] = weight\n",
    "new_fc.bias.data[:out_features] = bias\n",
    "\n",
    "# Replace the old FC layer\n",
    "model.classifier = new_fc\n",
    "model_old.classifier = new_fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1740666484886,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "YcOlndC4id2L",
    "outputId": "8499d8e4-2d0a-48f5-84a3-e77a4f03566c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'emb_dim': 300, 'n_heads': 8, 'dropout': 0.1, 'encoder_layers': 6}\n",
      "model params:  184190998\n"
     ]
    }
   ],
   "source": [
    "# Move to GPU, if available\n",
    "model_17 = model_17.to(device)\n",
    "model_18 = model_18.to(device)\n",
    "model_old = model_old.to(device)\n",
    "model = model.to(device)\n",
    "print(final_args)\n",
    "pytorch_total_params = sum(p.numel() for p in model.parameters())\n",
    "print('model params: ', pytorch_total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1740666484887,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "ISQnZUoridwD"
   },
   "outputs": [],
   "source": [
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1740666484899,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "hu_IIY0didor"
   },
   "outputs": [],
   "source": [
    "args.checkpoint_dir = '/content/drive/MyDrive/Colab Notebooks/research/multi-modality/endovis18/result/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "executionInfo": {
     "elapsed": 0,
     "status": "ok",
     "timestamp": 1740666484904,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "UNhclY-ziddC"
   },
   "outputs": [],
   "source": [
    "# best model initialize\n",
    "start_epoch = 1\n",
    "best_epoch = [0]\n",
    "best_results = [0.0]\n",
    "epochs_since_improvement = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "executionInfo": {
     "elapsed": 0,
     "status": "ok",
     "timestamp": 1740666484904,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "C2vwwczuidTE"
   },
   "outputs": [],
   "source": [
    "out_features = model.classifier.out_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uwkF9q7Mioho"
   },
   "source": [
    "soft target 和大模型准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "executionInfo": {
     "elapsed": 0,
     "status": "ok",
     "timestamp": 1740666484905,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "d6gQHt39DfXO"
   },
   "outputs": [],
   "source": [
    "from pandas.core.frame import DataFrame\n",
    "from sklearn.metrics import accuracy_score\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 586288,
     "status": "ok",
     "timestamp": 1740667071193,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "eisitO6HivDD",
    "outputId": "2f1df379-1708-4737-cf5f-ce4b144991ec"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "/usr/local/lib/python3.11/dist-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/local/lib/python3.11/dist-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "/usr/local/lib/python3.11/dist-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/local/lib/python3.11/dist-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "/usr/local/lib/python3.11/dist-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/local/lib/python3.11/dist-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "/usr/local/lib/python3.11/dist-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/local/lib/python3.11/dist-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "/usr/local/lib/python3.11/dist-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/local/lib/python3.11/dist-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "/usr/local/lib/python3.11/dist-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/local/lib/python3.11/dist-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "/usr/local/lib/python3.11/dist-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/local/lib/python3.11/dist-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "/usr/local/lib/python3.11/dist-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/local/lib/python3.11/dist-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "/usr/local/lib/python3.11/dist-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/local/lib/python3.11/dist-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "/usr/local/lib/python3.11/dist-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/local/lib/python3.11/dist-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "/usr/local/lib/python3.11/dist-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "label = []\n",
    "label_soft_list = [] #软标签（旧模型所得）\n",
    "\n",
    "for i, (_, visual_features, q, labels, t5_loss) in enumerate(train_dataloader_lrsp,0):\n",
    "\n",
    "    label_number = labels.numpy()[0]\n",
    "    label += labels.tolist()\n",
    "\n",
    "    # prepare questions\n",
    "    questions = []\n",
    "    for question in q: questions.append(question)\n",
    "    inputs = tokenizer(questions, return_tensors=\"pt\", padding=\"max_length\", max_length=args.question_len)\n",
    "\n",
    "    # GPU / CPU\n",
    "    visual_features = visual_features.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    soft_target = model_17(inputs, visual_features)\n",
    "    output_class_ranks = torch.argsort(soft_target, dim=-1, descending=True)\n",
    "\n",
    "    label_soft = []\n",
    "    for j in range(len(output_class_ranks)):\n",
    "        label_soft.append(int(output_class_ranks[j][0]))\n",
    "    label_soft_list += label_soft\n",
    "\n",
    "c={\"label\" : label, \"label_soft_list\" : label_soft_list}\n",
    "data=DataFrame(c)\n",
    "acc_soft = []\n",
    "for i in range(22):\n",
    "    label_part = []\n",
    "    label_soft_part = []\n",
    "    for j in range(len(data)):\n",
    "        if data.at[j,'label'] == i:\n",
    "            label_part.append(data.at[j,'label'])\n",
    "            label_soft_part.append(data.at[j,'label_soft_list'])\n",
    "    acc_soft.append(accuracy_score(label_part, label_soft_part))\n",
    "acc_soft_17 = [0 if math.isnan(x) else x for x in acc_soft]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12646,
     "status": "ok",
     "timestamp": 1740667083841,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "Azl7UquaU8Uo",
    "outputId": "7d7d3cf7-6bc8-43fa-887f-c19078846340"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "/usr/local/lib/python3.11/dist-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/local/lib/python3.11/dist-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "/usr/local/lib/python3.11/dist-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/local/lib/python3.11/dist-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "/usr/local/lib/python3.11/dist-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/local/lib/python3.11/dist-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "/usr/local/lib/python3.11/dist-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/local/lib/python3.11/dist-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "/usr/local/lib/python3.11/dist-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/local/lib/python3.11/dist-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "/usr/local/lib/python3.11/dist-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/local/lib/python3.11/dist-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "/usr/local/lib/python3.11/dist-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/local/lib/python3.11/dist-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "/usr/local/lib/python3.11/dist-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/local/lib/python3.11/dist-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "/usr/local/lib/python3.11/dist-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/local/lib/python3.11/dist-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "/usr/local/lib/python3.11/dist-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/local/lib/python3.11/dist-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "/usr/local/lib/python3.11/dist-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "label = []\n",
    "label_soft_list = [] #软标签（旧模型所得）\n",
    "\n",
    "for i, (_, visual_features, q, labels, t5_loss) in enumerate(train_dataloader_lrsp,0):\n",
    "\n",
    "    label_number = labels.numpy()[0]\n",
    "    label += labels.tolist()\n",
    "\n",
    "    # prepare questions\n",
    "    questions = []\n",
    "    for question in q: questions.append(question)\n",
    "    inputs = tokenizer(questions, return_tensors=\"pt\", padding=\"max_length\", max_length=args.question_len)\n",
    "\n",
    "    # GPU / CPU\n",
    "    visual_features = visual_features.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    soft_target = model_18(inputs, visual_features)\n",
    "    output_class_ranks = torch.argsort(soft_target, dim=-1, descending=True)\n",
    "\n",
    "    label_soft = []\n",
    "    for j in range(len(output_class_ranks)):\n",
    "        label_soft.append(int(output_class_ranks[j][0]))\n",
    "    label_soft_list += label_soft\n",
    "\n",
    "c={\"label\" : label, \"label_soft_list\" : label_soft_list}\n",
    "data=DataFrame(c)\n",
    "acc_soft = []\n",
    "for i in range(22):\n",
    "    label_part = []\n",
    "    label_soft_part = []\n",
    "    for j in range(len(data)):\n",
    "        if data.at[j,'label'] == i:\n",
    "            label_part.append(data.at[j,'label'])\n",
    "            label_soft_part.append(data.at[j,'label_soft_list'])\n",
    "    acc_soft.append(accuracy_score(label_part, label_soft_part))\n",
    "acc_soft_18 = [0 if math.isnan(x) else x for x in acc_soft]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12736,
     "status": "ok",
     "timestamp": 1740667096578,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "NtT-03X4VDUz",
    "outputId": "5d77b966-74f5-45ef-b55f-5668b88a32cb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "/usr/local/lib/python3.11/dist-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/local/lib/python3.11/dist-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "/usr/local/lib/python3.11/dist-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/local/lib/python3.11/dist-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "/usr/local/lib/python3.11/dist-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/local/lib/python3.11/dist-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "/usr/local/lib/python3.11/dist-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/local/lib/python3.11/dist-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "/usr/local/lib/python3.11/dist-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/local/lib/python3.11/dist-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "/usr/local/lib/python3.11/dist-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/local/lib/python3.11/dist-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "/usr/local/lib/python3.11/dist-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/local/lib/python3.11/dist-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "/usr/local/lib/python3.11/dist-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/local/lib/python3.11/dist-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "/usr/local/lib/python3.11/dist-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/local/lib/python3.11/dist-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "/usr/local/lib/python3.11/dist-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/local/lib/python3.11/dist-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "/usr/local/lib/python3.11/dist-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "label = []\n",
    "label_soft_list = [] #软标签（旧模型所得）\n",
    "\n",
    "for i, (_, visual_features, q, labels, t5_loss) in enumerate(train_dataloader_lrsp,0):\n",
    "\n",
    "    label_number = labels.numpy()[0]\n",
    "    label += labels.tolist()\n",
    "\n",
    "    # prepare questions\n",
    "    questions = []\n",
    "    for question in q: questions.append(question)\n",
    "    inputs = tokenizer(questions, return_tensors=\"pt\", padding=\"max_length\", max_length=args.question_len)\n",
    "\n",
    "    # GPU / CPU\n",
    "    visual_features = visual_features.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    soft_target = model_old(inputs, visual_features)\n",
    "    output_class_ranks = torch.argsort(soft_target, dim=-1, descending=True)\n",
    "\n",
    "    label_soft = []\n",
    "    for j in range(len(output_class_ranks)):\n",
    "        label_soft.append(int(output_class_ranks[j][0]))\n",
    "    label_soft_list += label_soft\n",
    "\n",
    "c={\"label\" : label, \"label_soft_list\" : label_soft_list}\n",
    "data=DataFrame(c)\n",
    "acc_soft = []\n",
    "for i in range(22):\n",
    "    label_part = []\n",
    "    label_soft_part = []\n",
    "    for j in range(len(data)):\n",
    "        if data.at[j,'label'] == i:\n",
    "            label_part.append(data.at[j,'label'])\n",
    "            label_soft_part.append(data.at[j,'label_soft_list'])\n",
    "    acc_soft.append(accuracy_score(label_part, label_soft_part))\n",
    "acc_soft_old = [0 if math.isnan(x) else x for x in acc_soft]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "executionInfo": {
     "elapsed": 3179,
     "status": "ok",
     "timestamp": 1740667099758,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "eu5lvRiti29y"
   },
   "outputs": [],
   "source": [
    "label = []\n",
    "label_llm_list = []\n",
    "\n",
    "for i, (_, visual_features, q, labels, t5_loss) in enumerate(train_dataloader_lrsp,0):\n",
    "  label += labels.tolist()\n",
    "\n",
    "  t5_loss_list = []\n",
    "  for j in range(len(t5_loss)):\n",
    "    #tmp = str2list(t5_loss[j])\n",
    "    tmp = t5_loss[j][:22]\n",
    "    t5_loss_list.append(tmp)\n",
    "\n",
    "  check = np.reciprocal(t5_loss_list)\n",
    "  t5_loss_tensor = torch.tensor(check)\n",
    "  output_class_ranks = torch.argsort(t5_loss_tensor, dim=-1, descending=True)\n",
    "\n",
    "  label_llm = []\n",
    "  for j in range(len(output_class_ranks)):\n",
    "    label_llm.append(int(output_class_ranks[j][0]))\n",
    "\n",
    "  label_llm_list += label_llm\n",
    "\n",
    "c={\"label\" : label, \"label_llm_list\" : label_llm_list}\n",
    "data=DataFrame(c)\n",
    "\n",
    "acc_llm = []\n",
    "\n",
    "for i in range(22):\n",
    "  label_part = []\n",
    "  label_llm_part = []\n",
    "\n",
    "  for j in range(len(data)):\n",
    "    if data.at[j,'label'] == i:\n",
    "      label_part.append(data.at[j,'label'])\n",
    "      label_llm_part.append(data.at[j,'label_llm_list'])\n",
    "\n",
    "  if len(label_part) == 0:\n",
    "    acc_llm.append(0)\n",
    "  else:\n",
    "    acc_llm.append(accuracy_score(label_part, label_llm_part))\n",
    "\n",
    "acc_llm = [0 if math.isnan(x) else x for x in acc_llm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1740667099784,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "owQO074p8z6z",
    "outputId": "151ff8d2-7b4e-4bb5-b207-25512f13829e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0.9871794871794872,\n",
       " 0.00980392156862745,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_soft_17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1740667099786,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "DxNPnap2VNwt",
    "outputId": "8b8b9299-68ce-409a-f119-b096d9fd46dd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0.9871794871794872,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_soft_18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1740667099788,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "AMN7DBwuVPbt",
    "outputId": "d356a917-fc96-4a07-f2d4-5ff7a1dbe571"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_soft_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1740667099790,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "rnkO8UwuVMxk"
   },
   "outputs": [],
   "source": [
    "acc_soft = [(x + y + z) / 3 for x, y, z in zip(acc_soft_17, acc_soft_18, acc_soft_old)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1740667099792,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "nMHNmSU2dyJq",
    "outputId": "7c670258-3e41-4380-978e-2c8de754b84a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.9914529914529915,\n",
       " 0.0032679738562091504,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_soft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bmDsgP4Sy2j5"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1740667099807,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "YHKzeLy-85Cb",
    "outputId": "93725741-f9ed-47a0-d4a5-e278cfb8041c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0.7910447761194029,\n",
       " 0.581081081081081,\n",
       " 1.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1740667099809,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "I6fgASYVi9Pb"
   },
   "outputs": [],
   "source": [
    "#To reduce the time of assessing the old model, we only caculate once in the first time.\n",
    "# acc_soft_17=[0,0.9875,0.010638297872340425,0.0,0.0,0.0,0,0.0,0,0,0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0]\n",
    "# acc_soft_18=[0,0.9875,0.0,0.0,0.0,0.0,0,0.0,0,0,0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0]\n",
    "# acc_soft_old=[0,0.9375,0.0,0.0,0.0,0.0,0,0.0,0,0,0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0]\n",
    "# acc_soft=[0.0,0.9708333333333333,0.0035460992907801418,0.0,0.0,0.0,0,0.0,0,0,0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0]\n",
    "# acc_llm=[0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0,0,0,0.7647058823529411,0.6282051282051282,1.0,0.0]\n",
    "\n",
    "from pandas.core.frame import DataFrame\n",
    "from sklearn.metrics import accuracy_score\n",
    "import math\n",
    "\n",
    "c={\"acc_soft\" : acc_soft, \"acc_llm\" : acc_llm}\n",
    "\n",
    "weight_data_17_18_daisi=DataFrame(c)\n",
    "\n",
    "\n",
    "for i in range(len(weight_data_17_18_daisi)):\n",
    "  if weight_data_17_18_daisi.at[i,'acc_soft'] + weight_data_17_18_daisi.at[i,'acc_llm'] == 0:\n",
    "    weight_data_17_18_daisi.at[i,'DS_soft'] = 0.5*(1 - hard_label_weight)\n",
    "    weight_data_17_18_daisi.at[i,'DS_llm'] = 0.5*(1 - hard_label_weight)\n",
    "  else:\n",
    "    weight_data_17_18_daisi.at[i,'DS_soft'] = (1-hard_label_weight) * weight_data_17_18_daisi.at[i,'acc_soft'] / (weight_data_17_18_daisi.at[i,'acc_soft'] + weight_data_17_18_daisi.at[i,'acc_llm'])\n",
    "    weight_data_17_18_daisi.at[i,'DS_llm'] = (1-hard_label_weight) * weight_data_17_18_daisi.at[i,'acc_llm'] / (weight_data_17_18_daisi.at[i,'acc_soft'] + weight_data_17_18_daisi.at[i,'acc_llm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "executionInfo": {
     "elapsed": 0,
     "status": "ok",
     "timestamp": 1740667099810,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "QzZvYsmzjEkN"
   },
   "outputs": [],
   "source": [
    "#weight processing\n",
    "weight_data_17_18_daisi['DI_soft']=(1-hard_label_weight) * (1 / (1 + ln_IR_17_18_daisi_d4))\n",
    "weight_data_17_18_daisi['DI_llm'] = (1-hard_label_weight) * ((ln_IR_17_18_daisi_d4) / (1 + ln_IR_17_18_daisi_d4))\n",
    "weight_data_17_18_daisi['weight_true_label']=hard_label_weight\n",
    "weight_data_17_18_daisi['weight_soft'] = DS_weight * weight_data_17_18_daisi['DS_soft'] + DI_weight * weight_data_17_18_daisi['DI_soft']\n",
    "weight_data_17_18_daisi['weight_llm'] = DS_weight * weight_data_17_18_daisi['DS_llm'] + DI_weight * weight_data_17_18_daisi['DI_llm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1740667099813,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "4q8aJFUljEdj",
    "outputId": "7427a5c4-37db-4c74-e45c-ddd86fe11dbe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-51-2fa82b5046a2>:2: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  acc_weight.weight_data_17_18_daisi = ['weight_true_label','weight_soft','weight_llm']\n"
     ]
    }
   ],
   "source": [
    "acc_weight = weight_data_17_18_daisi[['weight_true_label','weight_soft','weight_llm']]\n",
    "acc_weight.weight_data_17_18_daisi = ['weight_true_label','weight_soft','weight_llm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 739
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1740667099834,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "8rZA1ZVCxT1H",
    "outputId": "f4077d3e-13b1-4e8d-d567-b00d2a9d4d72"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"acc_weight\",\n  \"rows\": 22,\n  \"fields\": [\n    {\n      \"column\": \"weight_true_label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.27269898775599e-16,\n        \"min\": 0.8,\n        \"max\": 0.8,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"weight_soft\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.043715431612177426,\n        \"min\": 0.01327348081908282,\n        \"max\": 0.1932734808190828,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.1032734808190828\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"weight_llm\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04371543161217743,\n        \"min\": 0.006726519180917175,\n        \"max\": 0.18672651918091718,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.006726519180917175\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "acc_weight"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-a4575c73-b3fa-489d-a949-f526aa705057\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight_true_label</th>\n",
       "      <th>weight_soft</th>\n",
       "      <th>weight_llm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.103273</td>\n",
       "      <td>0.096727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.193273</td>\n",
       "      <td>0.006727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.193273</td>\n",
       "      <td>0.006727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.103273</td>\n",
       "      <td>0.096727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.103273</td>\n",
       "      <td>0.096727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.103273</td>\n",
       "      <td>0.096727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.103273</td>\n",
       "      <td>0.096727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.103273</td>\n",
       "      <td>0.096727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.103273</td>\n",
       "      <td>0.096727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.103273</td>\n",
       "      <td>0.096727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.103273</td>\n",
       "      <td>0.096727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.103273</td>\n",
       "      <td>0.096727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.103273</td>\n",
       "      <td>0.096727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.103273</td>\n",
       "      <td>0.096727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.103273</td>\n",
       "      <td>0.096727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.103273</td>\n",
       "      <td>0.096727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.103273</td>\n",
       "      <td>0.096727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.103273</td>\n",
       "      <td>0.096727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.013273</td>\n",
       "      <td>0.186727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.013273</td>\n",
       "      <td>0.186727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.013273</td>\n",
       "      <td>0.186727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.103273</td>\n",
       "      <td>0.096727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a4575c73-b3fa-489d-a949-f526aa705057')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-a4575c73-b3fa-489d-a949-f526aa705057 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-a4575c73-b3fa-489d-a949-f526aa705057');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-6d0f5413-1d0b-453d-af7f-e3dc8ad16a2b\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6d0f5413-1d0b-453d-af7f-e3dc8ad16a2b')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-6d0f5413-1d0b-453d-af7f-e3dc8ad16a2b button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "    weight_true_label  weight_soft  weight_llm\n",
       "0                 0.8     0.103273    0.096727\n",
       "1                 0.8     0.193273    0.006727\n",
       "2                 0.8     0.193273    0.006727\n",
       "3                 0.8     0.103273    0.096727\n",
       "4                 0.8     0.103273    0.096727\n",
       "5                 0.8     0.103273    0.096727\n",
       "6                 0.8     0.103273    0.096727\n",
       "7                 0.8     0.103273    0.096727\n",
       "8                 0.8     0.103273    0.096727\n",
       "9                 0.8     0.103273    0.096727\n",
       "10                0.8     0.103273    0.096727\n",
       "11                0.8     0.103273    0.096727\n",
       "12                0.8     0.103273    0.096727\n",
       "13                0.8     0.103273    0.096727\n",
       "14                0.8     0.103273    0.096727\n",
       "15                0.8     0.103273    0.096727\n",
       "16                0.8     0.103273    0.096727\n",
       "17                0.8     0.103273    0.096727\n",
       "18                0.8     0.013273    0.186727\n",
       "19                0.8     0.013273    0.186727\n",
       "20                0.8     0.013273    0.186727\n",
       "21                0.8     0.103273    0.096727"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(weight_data_17_18_daisi)\n",
    "acc_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1740667099835,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "Fsikge2OhwUT"
   },
   "outputs": [],
   "source": [
    "# d-daisi\n",
    "class DaisiVQADataset_old(Dataset):\n",
    "    def __init__(self, csv_file, data_type, patch_size=5):\n",
    "        self.patch_size = patch_size\n",
    "        tmp = pd.read_csv(csv_file)\n",
    "        self.data_frame = tmp[tmp['type']==data_type]\n",
    "        unique_files = len(self.data_frame['path'].unique())\n",
    "        total_questions = len(self.data_frame)\n",
    "        print(f\"Total files: {unique_files} | Total questions: {total_questions}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data_frame.iloc[idx]\n",
    "        q = sample['q']\n",
    "        labels = torch.tensor(sample['labels'])\n",
    "        file_name = str(sample['path'])\n",
    "\n",
    "        visual_feature_loc = '/' + os.path.join('content/drive/MyDrive/Colab Notebooks/research/multi-modality/daisi_vqa_final/data/',file_name,'vqa/img_features',(str(self.patch_size)+'x'+str(self.patch_size)),file_name+'.hdf5')\n",
    "        frame_data = h5py.File(visual_feature_loc, 'r')\n",
    "        visual_features = torch.from_numpy(frame_data['visual_features'][:])\n",
    "\n",
    "        t5_loss = torch.tensor(eval(sample['t5_loss']))\n",
    "\n",
    "        return file_name, visual_features, q, labels, t5_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 252284,
     "status": "ok",
     "timestamp": 1740667352119,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "EMGypmxy0TuA",
    "outputId": "e656d79b-53aa-43df-d152-1bc5099b4352"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files: 24 | Total question: 96\n",
      "Total files: 447 | Total question: 2769\n",
      "Total files: 114 | Total questions: 114\n"
     ]
    }
   ],
   "source": [
    "val_dataset_d4 = LrspDataset('/content/drive/MyDrive/Colab Notebooks/research/multi-modality/dataset_4/data.csv','val',patch_size=5)\n",
    "val_dataloader_d4 = DataLoader(dataset=val_dataset_d4, batch_size=1, shuffle=False)\n",
    "\n",
    "\n",
    "val_dataset_17 = EndoVis17VQAClassification([8],'/content/drive/MyDrive/Colab Notebooks/research/multi-modality/endovis17/seq_',\n",
    "                        '/vqa/*.txt', patch_size = 5)\n",
    "val_dataloader_17 = DataLoader(dataset=val_dataset_17, batch_size= 64, shuffle=False)\n",
    "\n",
    "\n",
    "val_dataset_18 = EndoVis18VQAClassification([1,5,16],'/content/drive/MyDrive/Colab Notebooks/research/multi-modality/endovis18/seq_',\n",
    "                          '/vqa/Classification_t5_loss/*.txt', patch_size = 5)\n",
    "val_dataloader_18 = DataLoader(dataset=val_dataset_18, batch_size= 64, shuffle=False)\n",
    "\n",
    "val_dataset_daisi = DaisiVQADataset_old('/content/drive/MyDrive/Colab Notebooks/research/multi-modality/daisi_vqa_final/daisi_data.csv',\n",
    "                                        'val',patch_size=5)\n",
    "val_dataloader_daisi = DataLoader(dataset=val_dataset_daisi, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1740667352122,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "_AOQa692DBkx"
   },
   "outputs": [],
   "source": [
    "# len(val_dataset_d4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QIKNk_2xjEM0",
    "outputId": "8e5c98b9-b8b1-4721-caad-1c323926d4ea"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/Colab Notebooks/research/multi-modality/endovis18/Surgical_VQA/utils.py:117: RuntimeWarning: invalid value encountered in divide\n",
      "  classwise_acc = matrix.diagonal()/matrix.sum(axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: epoch: 1 loss: 3333.961241 | Acc: 0.375415 | Precision: 0.367039 | Recall: 0.369878 | FScore: 0.283158\n",
      "Test: epoch: 1 loss: 5.608076 | Acc: 0.187500 | Precision: 0.646739 | Recall: 0.338462 | FScore: 0.070303\n",
      "Test: epoch: 1 loss: 138.561397 | Acc: 0.159624 | Precision: 0.750717 | Recall: 0.194568 | FScore: 0.055394\n",
      "Test: epoch: 1 loss: 95.721806 | Acc: 0.657895 | Precision: 0.665833 | Recall: 0.460764 | FScore: 0.256613\n",
      "Test: epoch: 1 loss: 183.085327 | Acc: 0.574713 | Precision: 0.741279 | Recall: 0.507312 | FScore: 0.461125\n",
      "epoch: 1 | Average acc: 0.394933\n",
      "epoch: 1 | Average fscore: 0.210859\n",
      "Train: epoch: 2 loss: 3035.447596 | Acc: 0.558140 | Precision: 0.547127 | Recall: 0.460991 | FScore: 0.452428\n",
      "Test: epoch: 2 loss: 5.806642 | Acc: 0.041667 | Precision: 0.680556 | Recall: 0.333333 | FScore: 0.023810\n",
      "Test: epoch: 2 loss: 141.567598 | Acc: 0.020224 | Precision: 0.714467 | Recall: 0.235929 | FScore: 0.012406\n",
      "Test: epoch: 2 loss: 124.481569 | Acc: 0.429825 | Precision: 0.686726 | Recall: 0.400000 | FScore: 0.120988\n",
      "Test: epoch: 2 loss: 186.285763 | Acc: 0.609195 | Precision: 0.770905 | Recall: 0.457235 | FScore: 0.410029\n",
      "epoch: 2 | Average acc: 0.275228\n",
      "epoch: 2 | Average fscore: 0.141808\n",
      "Train: epoch: 3 loss: 2990.948117 | Acc: 0.585825 | Precision: 0.557397 | Recall: 0.483909 | FScore: 0.471730\n",
      "Test: epoch: 3 loss: 6.133353 | Acc: 0.041667 | Precision: 0.680556 | Recall: 0.333333 | FScore: 0.023810\n",
      "Test: epoch: 3 loss: 135.964388 | Acc: 0.039003 | Precision: 0.695129 | Recall: 0.284157 | FScore: 0.021873\n",
      "Test: epoch: 3 loss: 97.189781 | Acc: 0.657895 | Precision: 0.665727 | Recall: 0.471034 | FScore: 0.267285\n",
      "Test: epoch: 3 loss: 182.092092 | Acc: 0.557471 | Precision: 0.757385 | Recall: 0.471713 | FScore: 0.418467\n",
      "epoch: 3 | Average acc: 0.324009\n",
      "epoch: 3 | Average fscore: 0.182859\n",
      "Train: epoch: 4 loss: 2969.042427 | Acc: 0.602436 | Precision: 0.584745 | Recall: 0.502598 | FScore: 0.487516\n",
      "Test: epoch: 4 loss: 6.554998 | Acc: 0.114583 | Precision: 0.745833 | Recall: 0.270000 | FScore: 0.069748\n",
      "Test: epoch: 4 loss: 144.928332 | Acc: 0.067895 | Precision: 0.725920 | Recall: 0.199067 | FScore: 0.021800\n",
      "Test: epoch: 4 loss: 106.910151 | Acc: 0.473684 | Precision: 0.690741 | Recall: 0.416129 | FScore: 0.154692\n",
      "Test: epoch: 4 loss: 192.625218 | Acc: 0.597701 | Precision: 0.725392 | Recall: 0.476510 | FScore: 0.451459\n",
      "epoch: 4 | Average acc: 0.313466\n",
      "epoch: 4 | Average fscore: 0.174425\n",
      "Train: epoch: 5 loss: 2926.371588 | Acc: 0.610188 | Precision: 0.612097 | Recall: 0.520063 | FScore: 0.507928\n",
      "Test: epoch: 5 loss: 6.538777 | Acc: 0.062500 | Precision: 0.603448 | Recall: 0.290909 | FScore: 0.048013\n",
      "Test: epoch: 5 loss: 140.922191 | Acc: 0.052004 | Precision: 0.626504 | Recall: 0.233830 | FScore: 0.031379\n",
      "Test: epoch: 5 loss: 119.027066 | Acc: 0.543860 | Precision: 0.581633 | Recall: 0.534233 | FScore: 0.170247\n",
      "Test: epoch: 5 loss: 170.061201 | Acc: 0.614943 | Precision: 0.624199 | Recall: 0.488732 | FScore: 0.460925\n",
      "epoch: 5 | Average acc: 0.318327\n",
      "epoch: 5 | Average fscore: 0.177641\n",
      "Train: epoch: 6 loss: 2883.433990 | Acc: 0.640089 | Precision: 0.537957 | Recall: 0.555234 | FScore: 0.541571\n",
      "Test: epoch: 6 loss: 7.076128 | Acc: 0.072917 | Precision: 0.604798 | Recall: 0.416667 | FScore: 0.037698\n",
      "Test: epoch: 6 loss: 153.883264 | Acc: 0.091730 | Precision: 0.621146 | Recall: 0.319415 | FScore: 0.037286\n",
      "Test: epoch: 6 loss: 99.368553 | Acc: 0.692982 | Precision: 0.678066 | Recall: 0.481369 | FScore: 0.279364\n",
      "Test: epoch: 6 loss: 256.391571 | Acc: 0.534483 | Precision: 0.560867 | Recall: 0.534025 | FScore: 0.449946\n",
      "epoch: 6 | Average acc: 0.348028\n",
      "epoch: 6 | Average fscore: 0.201073\n",
      "\n",
      "DECAYING learning rate.\n",
      "The new learning rate is 0.000005\n",
      "\n",
      "Train: epoch: 7 loss: 2819.112530 | Acc: 0.681063 | Precision: 0.675862 | Recall: 0.605453 | FScore: 0.590196\n",
      "Test: epoch: 7 loss: 6.769326 | Acc: 0.093750 | Precision: 0.460545 | Recall: 0.413889 | FScore: 0.057821\n",
      "Test: epoch: 7 loss: 141.062168 | Acc: 0.084507 | Precision: 0.600557 | Recall: 0.263327 | FScore: 0.038362\n",
      "Test: epoch: 7 loss: 101.685518 | Acc: 0.675439 | Precision: 0.672696 | Recall: 0.472350 | FScore: 0.270713\n",
      "Test: epoch: 7 loss: 210.466358 | Acc: 0.540230 | Precision: 0.622517 | Recall: 0.475980 | FScore: 0.447722\n",
      "epoch: 7 | Average acc: 0.348481\n",
      "epoch: 7 | Average fscore: 0.203655\n",
      "Train: epoch: 8 loss: 2746.707905 | Acc: 0.743079 | Precision: 0.734086 | Recall: 0.671352 | FScore: 0.658340\n",
      "Test: epoch: 8 loss: 6.761940 | Acc: 0.093750 | Precision: 0.584908 | Recall: 0.368182 | FScore: 0.057692\n",
      "Test: epoch: 8 loss: 141.105328 | Acc: 0.075840 | Precision: 0.589494 | Recall: 0.254121 | FScore: 0.031493\n",
      "Test: epoch: 8 loss: 102.934963 | Acc: 0.649123 | Precision: 0.660508 | Recall: 0.465240 | FScore: 0.262853\n",
      "Test: epoch: 8 loss: 225.820077 | Acc: 0.568966 | Precision: 0.575244 | Recall: 0.480127 | FScore: 0.468684\n",
      "epoch: 8 | Average acc: 0.346919\n",
      "epoch: 8 | Average fscore: 0.205181\n",
      "Train: epoch: 9 loss: 2688.741889 | Acc: 0.779623 | Precision: 0.732809 | Recall: 0.710335 | FScore: 0.712075\n",
      "Test: epoch: 9 loss: 6.857433 | Acc: 0.104167 | Precision: 0.439685 | Recall: 0.328526 | FScore: 0.079182\n",
      "Test: epoch: 9 loss: 153.790502 | Acc: 0.066450 | Precision: 0.582334 | Recall: 0.261493 | FScore: 0.037845\n",
      "Test: epoch: 9 loss: 98.840024 | Acc: 0.675439 | Precision: 0.673597 | Recall: 0.471494 | FScore: 0.269786\n",
      "Test: epoch: 9 loss: 217.627905 | Acc: 0.637931 | Precision: 0.605257 | Recall: 0.527107 | FScore: 0.506084\n",
      "epoch: 9 | Average acc: 0.370997\n",
      "epoch: 9 | Average fscore: 0.223224\n",
      "Train: epoch: 10 loss: 2614.352575 | Acc: 0.833887 | Precision: 0.809677 | Recall: 0.797116 | FScore: 0.796746\n",
      "Test: epoch: 10 loss: 7.266150 | Acc: 0.072917 | Precision: 0.508959 | Recall: 0.327273 | FScore: 0.062041\n",
      "Test: epoch: 10 loss: 151.570673 | Acc: 0.124233 | Precision: 0.640552 | Recall: 0.222245 | FScore: 0.054586\n",
      "Test: epoch: 10 loss: 96.501850 | Acc: 0.649123 | Precision: 0.672591 | Recall: 0.454970 | FScore: 0.248984\n",
      "Test: epoch: 10 loss: 274.892334 | Acc: 0.591954 | Precision: 0.641830 | Recall: 0.574094 | FScore: 0.515043\n",
      "epoch: 10 | Average acc: 0.359557\n",
      "epoch: 10 | Average fscore: 0.220163\n",
      "Train: epoch: 11 loss: 2556.995517 | Acc: 0.867110 | Precision: 0.840421 | Recall: 0.831714 | FScore: 0.834924\n",
      "Test: epoch: 11 loss: 7.742771 | Acc: 0.104167 | Precision: 0.570458 | Recall: 0.315152 | FScore: 0.040998\n",
      "Test: epoch: 11 loss: 153.032235 | Acc: 0.159263 | Precision: 0.541456 | Recall: 0.232194 | FScore: 0.048947\n",
      "Test: epoch: 11 loss: 103.178070 | Acc: 0.666667 | Precision: 0.670175 | Recall: 0.467413 | FScore: 0.265526\n",
      "Test: epoch: 11 loss: 254.153673 | Acc: 0.603448 | Precision: 0.603232 | Recall: 0.565544 | FScore: 0.555890\n",
      "epoch: 11 | Average acc: 0.383386\n",
      "epoch: 11 | Average fscore: 0.227840\n",
      "\n",
      "DECAYING learning rate.\n",
      "The new learning rate is 0.000004\n",
      "\n",
      "Train: epoch: 12 loss: 2482.675000 | Acc: 0.912514 | Precision: 0.895133 | Recall: 0.898784 | FScore: 0.896728\n",
      "Test: epoch: 12 loss: 8.928843 | Acc: 0.062500 | Precision: 0.577506 | Recall: 0.290909 | FScore: 0.037115\n",
      "Test: epoch: 12 loss: 178.121843 | Acc: 0.040087 | Precision: 0.645539 | Recall: 0.243099 | FScore: 0.019775\n",
      "Test: epoch: 12 loss: 120.683912 | Acc: 0.631579 | Precision: 0.551215 | Recall: 0.553270 | FScore: 0.215205\n",
      "Test: epoch: 12 loss: 260.952467 | Acc: 0.609195 | Precision: 0.613557 | Recall: 0.508033 | FScore: 0.505734\n",
      "epoch: 12 | Average acc: 0.335840\n",
      "epoch: 12 | Average fscore: 0.194457\n",
      "Train: epoch: 13 loss: 2457.066332 | Acc: 0.939092 | Precision: 0.925207 | Recall: 0.923240 | FScore: 0.924128\n",
      "Test: epoch: 13 loss: 7.995622 | Acc: 0.114583 | Precision: 0.535380 | Recall: 0.379167 | FScore: 0.055072\n",
      "Test: epoch: 13 loss: 160.767008 | Acc: 0.080173 | Precision: 0.534494 | Recall: 0.258841 | FScore: 0.033832\n",
      "Test: epoch: 13 loss: 107.278253 | Acc: 0.640351 | Precision: 0.657421 | Recall: 0.462870 | FScore: 0.259916\n",
      "Test: epoch: 13 loss: 311.073630 | Acc: 0.540230 | Precision: 0.494271 | Recall: 0.459486 | FScore: 0.456776\n",
      "epoch: 13 | Average acc: 0.343834\n",
      "epoch: 13 | Average fscore: 0.201399\n",
      "Train: epoch: 14 loss: 2417.108398 | Acc: 0.960133 | Precision: 0.951853 | Recall: 0.952150 | FScore: 0.951987\n",
      "Test: epoch: 14 loss: 7.797068 | Acc: 0.104167 | Precision: 0.452214 | Recall: 0.383333 | FScore: 0.053472\n",
      "Test: epoch: 14 loss: 165.889427 | Acc: 0.042254 | Precision: 0.547564 | Recall: 0.270847 | FScore: 0.025455\n",
      "Test: epoch: 14 loss: 163.703631 | Acc: 0.500000 | Precision: 0.529304 | Recall: 0.516513 | FScore: 0.160241\n",
      "Test: epoch: 14 loss: 276.715850 | Acc: 0.557471 | Precision: 0.524451 | Recall: 0.439042 | FScore: 0.422410\n",
      "epoch: 14 | Average acc: 0.300973\n",
      "epoch: 14 | Average fscore: 0.165395\n",
      "Train: epoch: 15 loss: 2400.921776 | Acc: 0.970100 | Precision: 0.965041 | Recall: 0.962869 | FScore: 0.963788\n",
      "Test: epoch: 15 loss: 8.064268 | Acc: 0.104167 | Precision: 0.563636 | Recall: 0.272727 | FScore: 0.030303\n",
      "Test: epoch: 15 loss: 168.252218 | Acc: 0.099675 | Precision: 0.524353 | Recall: 0.226391 | FScore: 0.022962\n",
      "Test: epoch: 15 loss: 132.979327 | Acc: 0.649123 | Precision: 0.556262 | Recall: 0.554367 | FScore: 0.221973\n",
      "Test: epoch: 15 loss: 321.485647 | Acc: 0.551724 | Precision: 0.642575 | Recall: 0.488460 | FScore: 0.483638\n",
      "epoch: 15 | Average acc: 0.351172\n",
      "epoch: 15 | Average fscore: 0.189719\n",
      "Train: epoch: 16 loss: 2406.806418 | Acc: 0.966777 | Precision: 0.960343 | Recall: 0.960093 | FScore: 0.960138\n",
      "Test: epoch: 16 loss: 8.054470 | Acc: 0.104167 | Precision: 0.414549 | Recall: 0.407692 | FScore: 0.046072\n",
      "Test: epoch: 16 loss: 165.911726 | Acc: 0.069700 | Precision: 0.530158 | Recall: 0.259913 | FScore: 0.028014\n",
      "Test: epoch: 16 loss: 130.166684 | Acc: 0.640351 | Precision: 0.661460 | Recall: 0.467149 | FScore: 0.260714\n",
      "Test: epoch: 16 loss: 295.496959 | Acc: 0.557471 | Precision: 0.507311 | Recall: 0.464112 | FScore: 0.467889\n",
      "epoch: 16 | Average acc: 0.342922\n",
      "epoch: 16 | Average fscore: 0.200672\n",
      "\n",
      "DECAYING learning rate.\n",
      "The new learning rate is 0.000003\n",
      "\n",
      "Train: epoch: 17 loss: 2377.253922 | Acc: 0.985604 | Precision: 0.981857 | Recall: 0.983607 | FScore: 0.982669\n",
      "Test: epoch: 17 loss: 8.394794 | Acc: 0.104167 | Precision: 0.538431 | Recall: 0.230000 | FScore: 0.059048\n",
      "Test: epoch: 17 loss: 166.406765 | Acc: 0.071506 | Precision: 0.534532 | Recall: 0.263845 | FScore: 0.030922\n",
      "Test: epoch: 17 loss: 168.581463 | Acc: 0.552632 | Precision: 0.533883 | Recall: 0.531216 | FScore: 0.184868\n",
      "Test: epoch: 17 loss: 278.670610 | Acc: 0.597701 | Precision: 0.571139 | Recall: 0.494034 | FScore: 0.500183\n",
      "epoch: 17 | Average acc: 0.331501\n",
      "epoch: 17 | Average fscore: 0.193755\n",
      "Train: epoch: 18 loss: 2362.601039 | Acc: 0.991141 | Precision: 0.988283 | Recall: 0.990316 | FScore: 0.989235\n",
      "Test: epoch: 18 loss: 8.334515 | Acc: 0.093750 | Precision: 0.565909 | Recall: 0.263636 | FScore: 0.032727\n",
      "Test: epoch: 18 loss: 165.784141 | Acc: 0.068617 | Precision: 0.534250 | Recall: 0.262385 | FScore: 0.029597\n",
      "Test: epoch: 18 loss: 175.598022 | Acc: 0.535088 | Precision: 0.539773 | Recall: 0.527979 | FScore: 0.174390\n",
      "Test: epoch: 18 loss: 270.147738 | Acc: 0.632184 | Precision: 0.663684 | Recall: 0.508463 | FScore: 0.507797\n",
      "epoch: 18 | Average acc: 0.332410\n",
      "epoch: 18 | Average fscore: 0.186128\n",
      "Train: epoch: 19 loss: 2356.408871 | Acc: 0.995570 | Precision: 0.993776 | Recall: 0.991482 | FScore: 0.992591\n",
      "Test: epoch: 19 loss: 8.678100 | Acc: 0.104167 | Precision: 0.621277 | Recall: 0.200000 | FScore: 0.035088\n",
      "Test: epoch: 19 loss: 164.348637 | Acc: 0.093897 | Precision: 0.630459 | Recall: 0.227830 | FScore: 0.035502\n",
      "Test: epoch: 19 loss: 152.629768 | Acc: 0.640351 | Precision: 0.556405 | Recall: 0.556671 | FScore: 0.219128\n",
      "Test: epoch: 19 loss: 274.308197 | Acc: 0.614943 | Precision: 0.630568 | Recall: 0.518177 | FScore: 0.521429\n",
      "epoch: 19 | Average acc: 0.363339\n",
      "epoch: 19 | Average fscore: 0.202787\n",
      "Train: epoch: 20 loss: 2347.293921 | Acc: 0.997785 | Precision: 0.995974 | Recall: 0.995974 | FScore: 0.995974\n",
      "Test: epoch: 20 loss: 8.313280 | Acc: 0.104167 | Precision: 0.621739 | Recall: 0.200000 | FScore: 0.035714\n",
      "Test: epoch: 20 loss: 158.615885 | Acc: 0.094258 | Precision: 0.636691 | Recall: 0.229554 | FScore: 0.039907\n",
      "Test: epoch: 20 loss: 155.996857 | Acc: 0.605263 | Precision: 0.546834 | Recall: 0.546632 | FScore: 0.205421\n",
      "Test: epoch: 20 loss: 282.734913 | Acc: 0.574713 | Precision: 0.516701 | Recall: 0.485147 | FScore: 0.491828\n",
      "epoch: 20 | Average acc: 0.344600\n",
      "epoch: 20 | Average fscore: 0.193218\n",
      "Train: epoch: 21 loss: 2364.994390 | Acc: 0.991141 | Precision: 0.990657 | Recall: 0.988209 | FScore: 0.989400\n",
      "Test: epoch: 21 loss: 8.363658 | Acc: 0.104167 | Precision: 0.584795 | Recall: 0.300000 | FScore: 0.058275\n",
      "Test: epoch: 21 loss: 168.876170 | Acc: 0.057783 | Precision: 0.643843 | Recall: 0.223697 | FScore: 0.026741\n",
      "Test: epoch: 21 loss: 152.863977 | Acc: 0.605263 | Precision: 0.652716 | Recall: 0.455958 | FScore: 0.245385\n",
      "Test: epoch: 21 loss: 286.900429 | Acc: 0.586207 | Precision: 0.494951 | Recall: 0.481845 | FScore: 0.480167\n",
      "epoch: 21 | Average acc: 0.338355\n",
      "epoch: 21 | Average fscore: 0.202642\n",
      "\n",
      "DECAYING learning rate.\n",
      "The new learning rate is 0.000003\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(start_epoch, epoch_num): # train only a few epoch to reduce training time\n",
    "\n",
    "  if epochs_since_improvement > 0 and epochs_since_improvement % 5 == 0:\n",
    "    adjust_learning_rate(optimizer, 0.8)\n",
    "\n",
    "  # train\n",
    "  train_acc = train_d4(args, train_dataloader=train_dataloader_lrsp, model = model, criterion=criterion, optimizer=optimizer, epoch=epoch, tokenizer = tokenizer, device = device)\n",
    "\n",
    "  # validation\n",
    "  #test 17\n",
    "  test_acc_17, test_c_acc, test_precision, test_recall, test_fscore_17 = validate_17(args,val_loader=val_dataloader_17, model = model, criterion=criterion, epoch=epoch, tokenizer = tokenizer, device = device)\n",
    "\n",
    "  #test 18\n",
    "  test_acc_18, test_c_acc, test_precision, test_recall, test_fscore_18 = validate_18_d3_d4(args,val_loader=val_dataloader_18, model = model, criterion=criterion, epoch=epoch, tokenizer = tokenizer, device = device)\n",
    "\n",
    "  #test daisi\n",
    "  test_acc_daisi, test_c_acc, test_precision, test_recall, test_fscore_daisi = validate_18_d3_d4(args,val_loader=val_dataloader_daisi, model = model, criterion=criterion, epoch=epoch, tokenizer = tokenizer, device = device)\n",
    "\n",
    "  test_acc, test_c_acc, test_precision, test_recall, test_fscore_d4 = validate_18_d3_d4(args, val_loader=val_dataloader_d4, model = model, criterion=criterion, epoch=epoch, tokenizer = tokenizer, device = device)\n",
    "\n",
    "  test_acc_d4=test_acc\n",
    "\n",
    "  av_acc = (test_acc_d4+test_acc_17+test_acc_18+test_acc_daisi)/4\n",
    "  av_fscore = (test_fscore_d4+test_fscore_17+test_fscore_18+test_fscore_daisi)/4\n",
    "  print('epoch: %d | Average acc: %.6f' %(epoch, av_acc))\n",
    "  print('epoch: %d | Average fscore: %.6f' %(epoch, av_fscore))\n",
    "\n",
    "  if av_acc >= best_results[0]:\n",
    "    epochs_since_improvement = 0\n",
    "\n",
    "    best_results[0] = av_acc\n",
    "    best_epoch[0] = epoch\n",
    "    save_clf_checkpoint(args.checkpoint_dir, epoch, epochs_since_improvement, model, optimizer, best_results[0], final_args)\n",
    "\n",
    "  else:\n",
    "    epochs_since_improvement += 1\n",
    "\n",
    "  if train_acc >= 1.0: break"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPk5nQxqQVemx1R6PPg3A0A",
   "gpuType": "T4",
   "machine_shape": "hm",
   "mount_file_id": "1JgFydiRsPli5HMjb8bMdU1zZZZr7ezhe",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
