{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "46pNxfRKsBpD"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 0,
     "status": "ok",
     "timestamp": 1740666273242,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "SISMZXOwX-OH"
   },
   "outputs": [],
   "source": [
    "T=2\n",
    "N_Balance = 2000\n",
    "DS_weight=0.9\n",
    "DI_weight=0.1\n",
    "hard_label_weight=0.8\n",
    "epoch_num=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23788,
     "status": "ok",
     "timestamp": 1740666297030,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "mjvXse7NV23K",
    "outputId": "2085ba0b-48f6-4e05-ebe5-0b79f3195f86"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6475,
     "status": "ok",
     "timestamp": 1740666303506,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "WS66FegVV4_Z",
    "outputId": "377f8a81-c406-4dc4-df23-d34d4ab45aa4"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/content/drive/MyDrive/Colab Notebooks/research/multi-modality/endovis18\")\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from lib2to3.pytree import convert\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7326,
     "status": "ok",
     "timestamp": 1740666310838,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "0gLMdAW7W6oi",
    "outputId": "e54bb37e-5242-4768-b8d8-15eb8272c3db"
   },
   "outputs": [],
   "source": [
    "pip install transformers==4.18.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 16396,
     "status": "ok",
     "timestamp": 1740666327236,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "npAwHewjXC-5"
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "from torch.utils.data  import DataLoader\n",
    "import sys\n",
    "sys.path.append('/content/drive/MyDrive/Colab Notebooks/research/multi-modality/endovis18/Surgical_VQA')\n",
    "from utils import *\n",
    "from dataloaders.dataloaderClassification import *\n",
    "from models.VisualBertClassification import VisualBertClassification\n",
    "from models.VisualBertResMLPClassification import VisualBertResMLPClassification\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1740666327238,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "7mVVTF5OZNZS"
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed=27):\n",
    "    '''\n",
    "    Set random seed for reproducible experiments\n",
    "    Inputs: seed number\n",
    "    '''\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 0,
     "status": "ok",
     "timestamp": 1740666327239,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "LSmyDMWNZg4a"
   },
   "outputs": [],
   "source": [
    "# training function for our CL algorithm\n",
    "def train_d4(args, train_dataloader, model, criterion, optimizer, epoch, tokenizer, device):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    label_true = None\n",
    "    label_pred = None\n",
    "    label_score = None\n",
    "\n",
    "\n",
    "    for i, (_, visual_features, q, labels, t5_loss) in enumerate(train_dataloader,0):\n",
    "\n",
    "        label_number = labels.numpy()[0]\n",
    "\n",
    "        # prepare questions\n",
    "        questions = []\n",
    "        for question in q: questions.append(question)\n",
    "        inputs = tokenizer(questions, return_tensors=\"pt\", padding=\"max_length\", max_length=args.question_len)\n",
    "\n",
    "        # t5 loss\n",
    "        t5_loss_list = []\n",
    "        for j in range(len(t5_loss)):\n",
    "          #tmp = str2list(t5_loss[j])\n",
    "          tmp = t5_loss[j][:22]\n",
    "          t5_loss_list.append(tmp)\n",
    "        check = np.reciprocal(t5_loss_list)\n",
    "        t5_loss_tensor = torch.tensor(check)\n",
    "\n",
    "        t5_loss_tensor = t5_loss_tensor.to(device)\n",
    "\n",
    "        # GPU / CPU\n",
    "        visual_features = visual_features.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        #print(labels)\n",
    "\n",
    "        outputs = model(inputs, visual_features)\n",
    "\n",
    "        soft_target_17 = model_17(inputs, visual_features)\n",
    "        soft_target_18 = model_18(inputs, visual_features)\n",
    "        soft_target = model_old(inputs, visual_features)\n",
    "\n",
    "\n",
    "        loss1 = criterion(outputs, labels)\n",
    "\n",
    "        outputs_S = F.softmax(outputs[:,:out_features]/T,dim=1)\n",
    "\n",
    "        outputs_T_17 = F.softmax(soft_target_17[:,:out_features]/T,dim=1)\n",
    "        outputs_T_18 = F.softmax(soft_target_18[:,:out_features]/T,dim=1)\n",
    "        outputs_T = F.softmax(soft_target[:,:out_features]/T,dim=1)\n",
    "\n",
    "        outputs_t5_loss = F.softmax(t5_loss_tensor[:,:out_features]/T,dim=1)\n",
    "\n",
    "        loss2_17 = outputs_T_17.mul(-1*torch.log(outputs_S))\n",
    "        loss2_17 = loss2_17.sum(1)\n",
    "        loss2_17 = loss2_17.mean()*T*T\n",
    "\n",
    "        loss2_18 = outputs_T_18.mul(-1*torch.log(outputs_S))\n",
    "        loss2_18 = loss2_18.sum(1)\n",
    "        loss2_18 = loss2_18.mean()*T*T\n",
    "\n",
    "        loss2 = outputs_T.mul(-1*torch.log(outputs_S))\n",
    "        loss2 = loss2.sum(1)\n",
    "        loss2 = loss2.mean()*T*T\n",
    "\n",
    "        loss3 = outputs_t5_loss.mul(-1*torch.log(outputs_S))\n",
    "        loss3 = loss3.sum(1)\n",
    "        loss3 = loss3.mean()*T*T\n",
    "\n",
    "        #loss = loss1 * 0.8 + loss2 * 0.123 + loss3 * 0.077\n",
    "        #loss = loss1 * acc_weight.at[label_number,'weight_true_label'] + loss2_17 * (acc_weight.at[label_number,'weight_soft'])*0.05 + loss2_18 * (acc_weight.at[label_number,'weight_soft'])*0.05 + loss2 * (acc_weight.at[label_number,'weight_soft'])*0.9 + loss3 * acc_weight.at[label_number,'weight_llm']\n",
    "\n",
    "        loss = loss1 * acc_weight.at[label_number,'weight_true_label'] + loss2_17 * (acc_weight.at[label_number,'weight_soft'])/3 + loss2_18 * (acc_weight.at[label_number,'weight_soft'])/3 + loss2 * (acc_weight.at[label_number,'weight_soft'])/3 + loss3 * acc_weight.at[label_number,'weight_llm']\n",
    "\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        scores, predicted = torch.max(F.softmax(outputs, dim=1).data, 1)\n",
    "\n",
    "        #print(predicted)\n",
    "\n",
    "        label_true = labels.data.cpu() if label_true == None else torch.cat((label_true, labels.data.cpu()), 0)\n",
    "        label_pred = predicted.data.cpu() if label_pred == None else torch.cat((label_pred, predicted.data.cpu()), 0)\n",
    "        label_score = scores.data.cpu() if label_score == None else torch.cat((label_score, scores.data.cpu()), 0)\n",
    "\n",
    "    # loss and acc\n",
    "    acc, c_acc = calc_acc(label_true, label_pred), calc_classwise_acc(label_true, label_pred)\n",
    "    precision, recall, fscore = calc_precision_recall_fscore(label_true, label_pred)\n",
    "    print('Train: epoch: %d loss: %.6f | Acc: %.6f | Precision: %.6f | Recall: %.6f | FScore: %.6f' %(epoch, total_loss, acc, precision, recall, fscore))\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1740666327240,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "35lhtZgoZdnW"
   },
   "outputs": [],
   "source": [
    "def validate_17(args, val_loader, model, criterion, epoch, tokenizer, device, save_output = False):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    label_true = None\n",
    "    label_pred = None\n",
    "    label_score = None\n",
    "    file_names = list()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    convert_arr = ['kidney', 'Idle', 'Grasping', 'Retraction', 'Tissue_Manipulation',\n",
    "              'Tool_Manipulation', 'Cutting', 'Cauterization', 'Suction',\n",
    "               'Looping', 'Suturing', 'Clipping', 'Staple', 'Ultrasound_Sensing',\n",
    "              'left-top', 'right-top', 'left-bottom', 'right-bottom',\n",
    "                   'no', 'yes','left', 'right']\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (file_name, visual_features, q, labels) in enumerate(val_loader,0):\n",
    "            # prepare questions\n",
    "            questions = []\n",
    "            for question in q: questions.append(question)\n",
    "            inputs = tokenizer(questions, return_tensors=\"pt\", padding=\"max_length\", max_length=args.question_len)\n",
    "\n",
    "            # GPU / CPU\n",
    "            visual_features = visual_features.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs, visual_features)\n",
    "\n",
    "            #print(labels)\n",
    "\n",
    "            loss = criterion(outputs,labels)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            scores, predicted = torch.max(F.softmax(outputs, dim=1).data, 1)\n",
    "\n",
    "            #print(predicted)\n",
    "\n",
    "            label_true = labels.data.cpu() if label_true == None else torch.cat((label_true, labels.data.cpu()), 0)\n",
    "            label_pred = predicted.data.cpu() if label_pred == None else torch.cat((label_pred, predicted.data.cpu()), 0)\n",
    "            label_score = scores.data.cpu() if label_score == None else torch.cat((label_score, scores.data.cpu()), 0)\n",
    "            for f in file_name: file_names.append(f)\n",
    "\n",
    "    acc = calc_acc(label_true, label_pred)\n",
    "    c_acc = 0.0\n",
    "    # c_acc = calc_classwise_acc(label_true, label_pred)\n",
    "    precision, recall, fscore = calc_precision_recall_fscore(label_true, label_pred)\n",
    "\n",
    "    print('Test: epoch: %d loss: %.6f | Acc: %.6f | Precision: %.6f | Recall: %.6f | FScore: %.6f' %(epoch, total_loss, acc, precision, recall, fscore))\n",
    "\n",
    "    if save_output:\n",
    "        '''\n",
    "            Saving predictions\n",
    "        '''\n",
    "        if os.path.exists(args.checkpoint_dir + 'text_files') == False:\n",
    "            os.mkdir(args.checkpoint_dir + 'text_files' )\n",
    "        file1 = open(args.checkpoint_dir + 'text_files/labels.txt', 'w')\n",
    "        file1.write(str(label_true))\n",
    "        file1.close()\n",
    "\n",
    "        file1 = open(args.checkpoint_dir + 'text_files/predictions.txt', 'w')\n",
    "        file1.write(str(label_pred))\n",
    "        file1.close()\n",
    "\n",
    "        if args.dataset_type == 'med_vqa':\n",
    "            if args.dataset_cat == 'cat1':\n",
    "                convert_arr = ['cta - ct angiography', 'no', 'us - ultrasound', 'xr - plain film', 'noncontrast', 'yes', 't2', 'ct w/contrast (iv)', 'mr - flair', 'mammograph', 'ct with iv contrast',\n",
    "                            'gi and iv', 't1', 'mr - t2 weighted', 'mr - t1w w/gadolinium', 'contrast', 'iv', 'an - angiogram', 'mra - mr angiography/venography', 'nm - nuclear medicine', 'mr - dwi diffusion weighted',\n",
    "                            'ct - gi & iv contrast', 'ct noncontrast', 'mr - other pulse seq.', 'ct with gi and iv contrast', 'flair', 'mr - t1w w/gd (fat suppressed)', 'ugi - upper gi', 'mr - adc map (app diff coeff)',\n",
    "                            'bas - barium swallow', 'pet - positron emission', 'mr - pdw proton density', 'mr - t1w - noncontrast', 'be - barium enema', 'us-d - doppler ultrasound', 'mr - stir', 'mr - flair w/gd',\n",
    "                            'ct with gi contrast', 'venogram', 'mr t2* gradient,gre,mpgr,swan,swi', 'mr - fiesta', 'ct - myelogram', 'gi', 'sbft - small bowel', 'pet-ct fusion']\n",
    "            elif args.dataset_cat == 'cat2':\n",
    "                convert_arr = ['axial', 'longitudinal', 'coronal', 'lateral', 'ap', 'sagittal', 'mammo - mlo', 'pa', 'mammo - cc', 'transverse', 'mammo - mag cc', 'frontal', 'oblique', '3d reconstruction', 'decubitus', 'mammo - xcc']\n",
    "            else:\n",
    "                convert_arr = ['lung, mediastinum, pleura', 'skull and contents', 'genitourinary', 'spine and contents', 'musculoskeletal', 'heart and great vessels', 'vascular and lymphatic', 'gastrointestinal', 'face, sinuses, and neck', 'breast']\n",
    "        elif args.dataset_type == 'c80':\n",
    "            convert_arr = ['no', 'calot triangle dissection', 'yes', '1', '2', 'gallbladder dissection',\n",
    "                            'clipping cutting', 'gallbladder retraction', '0', 'cleaning coagulation',\n",
    "                            'gallbladder packaging', 'preparation', '3']\n",
    "        elif args.dataset_type == 'm18':\n",
    "            convert_arr = ['kidney', 'Idle', 'Grasping', 'Retraction', 'Tissue_Manipulation',\n",
    "                            'Tool_Manipulation', 'Cutting', 'Cauterization', 'Suction',\n",
    "                            'Looping', 'Suturing', 'Clipping', 'Staple', 'Ultrasound_Sensing',\n",
    "                            'left-top', 'right-top', 'left-bottom', 'right-bottom']\n",
    "\n",
    "        df = pd.DataFrame(columns=[\"Img\", \"Ground Truth\", \"Prediction\"])\n",
    "        for i in range(len(label_true)):\n",
    "            df = df.append({'Img': file_names[i], 'Ground Truth': convert_arr[label_true[i]], 'Prediction': convert_arr[label_pred[i]]}, ignore_index=True)\n",
    "\n",
    "        df.to_csv(args.checkpoint_dir + args.checkpoint_dir.split('/')[1] + '_' + args.checkpoint_dir.split('/')[2] + '_eval.csv')\n",
    "\n",
    "    return (acc, c_acc, precision, recall, fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1740666327254,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "iO22hFlWZs7g"
   },
   "outputs": [],
   "source": [
    "def validate_18_d3_d4(args, val_loader, model, criterion, epoch, tokenizer, device, save_output = False):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    label_true = None\n",
    "    label_pred = None\n",
    "    label_score = None\n",
    "    file_names = list()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (file_name, visual_features, q, labels, _) in enumerate(val_loader,0):\n",
    "            # prepare questions\n",
    "            questions = []\n",
    "            for question in q: questions.append(question)\n",
    "            inputs = tokenizer(questions, return_tensors=\"pt\", padding=\"max_length\", max_length=args.question_len)\n",
    "\n",
    "            # GPU / CPU\n",
    "            visual_features = visual_features.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs, visual_features)\n",
    "\n",
    "\n",
    "            loss = criterion(outputs,labels)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            scores, predicted = torch.max(F.softmax(outputs, dim=1).data, 1)\n",
    "\n",
    "\n",
    "            label_true = labels.data.cpu() if label_true == None else torch.cat((label_true, labels.data.cpu()), 0)\n",
    "            label_pred = predicted.data.cpu() if label_pred == None else torch.cat((label_pred, predicted.data.cpu()), 0)\n",
    "            label_score = scores.data.cpu() if label_score == None else torch.cat((label_score, scores.data.cpu()), 0)\n",
    "            for f in file_name: file_names.append(f)\n",
    "\n",
    "    acc = calc_acc(label_true, label_pred)\n",
    "    c_acc = 0.0\n",
    "    # c_acc = calc_classwise_acc(label_true, label_pred)\n",
    "    precision, recall, fscore = calc_precision_recall_fscore(label_true, label_pred)\n",
    "\n",
    "    print('Test: epoch: %d loss: %.6f | Acc: %.6f | Precision: %.6f | Recall: %.6f | FScore: %.6f' %(epoch, total_loss, acc, precision, recall, fscore))\n",
    "\n",
    "    if save_output:\n",
    "        '''\n",
    "            Saving predictions\n",
    "        '''\n",
    "        if os.path.exists(args.checkpoint_dir + 'text_files') == False:\n",
    "            os.mkdir(args.checkpoint_dir + 'text_files' )\n",
    "        file1 = open(args.checkpoint_dir + 'text_files/labels.txt', 'w')\n",
    "        file1.write(str(label_true))\n",
    "        file1.close()\n",
    "\n",
    "        file1 = open(args.checkpoint_dir + 'text_files/predictions.txt', 'w')\n",
    "        file1.write(str(label_pred))\n",
    "        file1.close()\n",
    "\n",
    "        if args.dataset_type == 'med_vqa':\n",
    "            if args.dataset_cat == 'cat1':\n",
    "                convert_arr = ['cta - ct angiography', 'no', 'us - ultrasound', 'xr - plain film', 'noncontrast', 'yes', 't2', 'ct w/contrast (iv)', 'mr - flair', 'mammograph', 'ct with iv contrast',\n",
    "                            'gi and iv', 't1', 'mr - t2 weighted', 'mr - t1w w/gadolinium', 'contrast', 'iv', 'an - angiogram', 'mra - mr angiography/venography', 'nm - nuclear medicine', 'mr - dwi diffusion weighted',\n",
    "                            'ct - gi & iv contrast', 'ct noncontrast', 'mr - other pulse seq.', 'ct with gi and iv contrast', 'flair', 'mr - t1w w/gd (fat suppressed)', 'ugi - upper gi', 'mr - adc map (app diff coeff)',\n",
    "                            'bas - barium swallow', 'pet - positron emission', 'mr - pdw proton density', 'mr - t1w - noncontrast', 'be - barium enema', 'us-d - doppler ultrasound', 'mr - stir', 'mr - flair w/gd',\n",
    "                            'ct with gi contrast', 'venogram', 'mr t2* gradient,gre,mpgr,swan,swi', 'mr - fiesta', 'ct - myelogram', 'gi', 'sbft - small bowel', 'pet-ct fusion']\n",
    "            elif args.dataset_cat == 'cat2':\n",
    "                convert_arr = ['axial', 'longitudinal', 'coronal', 'lateral', 'ap', 'sagittal', 'mammo - mlo', 'pa', 'mammo - cc', 'transverse', 'mammo - mag cc', 'frontal', 'oblique', '3d reconstruction', 'decubitus', 'mammo - xcc']\n",
    "            else:\n",
    "                convert_arr = ['lung, mediastinum, pleura', 'skull and contents', 'genitourinary', 'spine and contents', 'musculoskeletal', 'heart and great vessels', 'vascular and lymphatic', 'gastrointestinal', 'face, sinuses, and neck', 'breast']\n",
    "        elif args.dataset_type == 'c80':\n",
    "            convert_arr = ['no', 'calot triangle dissection', 'yes', '1', '2', 'gallbladder dissection',\n",
    "                            'clipping cutting', 'gallbladder retraction', '0', 'cleaning coagulation',\n",
    "                            'gallbladder packaging', 'preparation', '3']\n",
    "        elif args.dataset_type == 'm18':\n",
    "            convert_arr = ['kidney', 'Idle', 'Grasping', 'Retraction', 'Tissue_Manipulation',\n",
    "                            'Tool_Manipulation', 'Cutting', 'Cauterization', 'Suction',\n",
    "                            'Looping', 'Suturing', 'Clipping', 'Staple', 'Ultrasound_Sensing',\n",
    "                            'left-top', 'right-top', 'left-bottom', 'right-bottom']\n",
    "\n",
    "        df = pd.DataFrame(columns=[\"Img\", \"Ground Truth\", \"Prediction\"])\n",
    "        for i in range(len(label_true)):\n",
    "            df = df.append({'Img': file_names[i], 'Ground Truth': convert_arr[label_true[i]], 'Prediction': convert_arr[label_pred[i]]}, ignore_index=True)\n",
    "\n",
    "        df.to_csv(args.checkpoint_dir + args.checkpoint_dir.split('/')[1] + '_' + args.checkpoint_dir.split('/')[2] + '_eval.csv')\n",
    "\n",
    "    return (acc, c_acc, precision, recall, fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 0,
     "status": "ok",
     "timestamp": 1740666327254,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "2U0-bmYrZwAy"
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='VisualQuestionAnswerClassification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1740666327257,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "jFwtYN9BZ-kq",
    "outputId": "ed5ffce0-d847-44dc-cae3-e16bf13bb27d"
   },
   "outputs": [],
   "source": [
    "parser.add_argument('--emb_dim',     type=int,  default=300, help='dimension of word embeddings.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1740666327258,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "zfkYxKvtZ-Sp",
    "outputId": "23dd9198-e327-4047-d9f0-99cd46441c8e"
   },
   "outputs": [],
   "source": [
    "parser.add_argument('--n_heads',     type=int,  default=8,  help='Multi-head attention.')\n",
    "parser.add_argument('--dropout',     type=float, default=0.1, help='dropout')\n",
    "parser.add_argument('--encoder_layers',  type=int,  default=6,  help='the number of layers of encoder in Transformer.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1740666327264,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "7FAcRqTwaaO3",
    "outputId": "ae8f2017-ad03-41e8-acfd-b6e3a96313ed"
   },
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "parser.add_argument('--epochs',       type=int,   default=80,     help='number of epochs to train for (if early stopping is not triggered).') #80, 26\n",
    "parser.add_argument('--batch_size',     type=int,   default=64,      help='batch_size')\n",
    "parser.add_argument('--workers',      type=int,   default=1,     help='for data-loading; right now, only 1 works with h5pys.')\n",
    "parser.add_argument('--print_freq',     type=int,   default=100,     help='print training/validation stats every __ batches.')\n",
    "\n",
    "# existing checkpoint\n",
    "parser.add_argument('--checkpoint',     default=None,             help='path to checkpoint, None if none.')\n",
    "\n",
    "parser.add_argument('--lr', type=float,  default=0.00001, help='0.000005, 0.00001, 0.000005')\n",
    "parser.add_argument('--checkpoint_dir',   default= '/content/drive/MyDrive/Colab Notebooks/research/multi-modality/endovis18/result/',    help='med_vqa_c$version$/m18/c80//m18_vid$temporal_size$/c80_vid$temporal_size$') #clf_v1_2_1x1/med_vqa_c3\n",
    "parser.add_argument('--dataset_type',    default= 'm18',         help='med_vqa/m18/c80/m18_vid/c80_vid')\n",
    "parser.add_argument('--dataset_cat',    default= 'None',         help='cat1/cat2/cat3')\n",
    "parser.add_argument('--transformer_ver',  default= 'vbrm',         help='vb/vbrm')\n",
    "parser.add_argument('--tokenizer_ver',   default= 'v2',          help='v2/v3')\n",
    "parser.add_argument('--patch_size',     default= 5,           help='1/2/3/4/5')\n",
    "parser.add_argument('--temporal_size',   default= 3,           help='1/2/3/4/5')\n",
    "parser.add_argument('--question_len',    default= 25,          help='25')\n",
    "parser.add_argument('--num_class',     default= 2,           help='25')\n",
    "parser.add_argument('--validate',      default=False,          help='When only validation required False/True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1740666327267,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "d9GEDvXfbS4a",
    "outputId": "f2f2a254-4727-4caa-97b8-f0b562d7a146"
   },
   "outputs": [],
   "source": [
    "parser.add_argument('-f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 0,
     "status": "ok",
     "timestamp": 1740666327267,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "injs_EEEbXEy"
   },
   "outputs": [],
   "source": [
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1740666327274,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "jH_3QP_9bcE0"
   },
   "outputs": [],
   "source": [
    "# load checkpoint, these parameters can't be modified\n",
    "final_args = {\"emb_dim\": 300, \"n_heads\": 8, \"dropout\": 0.1, \"encoder_layers\": 6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1740666327279,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "XYYWg4abbf8U"
   },
   "outputs": [],
   "source": [
    "seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1740666327280,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "baxNHnoabiN2",
    "outputId": "df432691-ba42-4bdf-f367-c6c6d4d7b2af"
   },
   "outputs": [],
   "source": [
    "# GPU or CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # sets device for model and PyTorch tensors\n",
    "cudnn.benchmark = True  # set to true only if inputs to model are fixed size; otherwise lot of computational overhead\n",
    "print('device =', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1740666327288,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "pHTkp2NSbma-"
   },
   "outputs": [],
   "source": [
    "# best model initialize\n",
    "start_epoch = 1\n",
    "best_epoch = [0]\n",
    "best_results = [0.0]\n",
    "epochs_since_improvement = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2741,
     "status": "ok",
     "timestamp": 1740666330029,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "R4Zfn7fHboTq"
   },
   "outputs": [],
   "source": [
    "# tokenizer\n",
    "tokenizer = None\n",
    "tokenizer = BertTokenizer.from_pretrained(\"/content/drive/MyDrive/Colab Notebooks/research/multi-modality/endovis18\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1740666330039,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "vjC-eg_YdL7E",
    "outputId": "5346e040-c4e5-4924-fc9c-02b782173580"
   },
   "outputs": [],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1740666330041,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "M7i8942GdZDy"
   },
   "outputs": [],
   "source": [
    "args.num_class = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3132,
     "status": "ok",
     "timestamp": 1740666333173,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "l-3t1VlVdcOL"
   },
   "outputs": [],
   "source": [
    "#if args.transformer_ver == 'vb':\n",
    "model = VisualBertClassification(vocab_size=len(tokenizer), layers=6, n_heads=8, num_class = args.num_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1740666333176,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "iLutJbeodgdC"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1740666333177,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "reTeLejRdj24"
   },
   "outputs": [],
   "source": [
    "# 将一个表示浮点数列表的字符串转换为实际的浮点数列表\n",
    "def str2list(target_str):\n",
    "  res=target_str.strip('[')\n",
    "  res=res.strip(']')\n",
    "  res=res.split(',')\n",
    "\n",
    "  for i in range(len(res)):\n",
    "    res[i] = res[i].strip() # 去掉空格\n",
    "\n",
    "  new_list = [float(x) for x in res]\n",
    "  return new_list[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mWMuLIWDdoE_"
   },
   "source": [
    "Imbalance Issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 613,
     "status": "ok",
     "timestamp": 1740666333790,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "6ga6aYE6d1gh",
    "outputId": "31c41e0b-aefd-4736-eac9-74491d623e9d"
   },
   "outputs": [],
   "source": [
    "# Since the three dataset is already fixed, we pre-store the label distribution in a CSV file to save the time loading all the data\n",
    "# Load all the data will be a VERY time-consuming in Colab\n",
    "import math\n",
    "\n",
    "frequency_all = pd.read_csv(\"frequency_all.csv\")\n",
    "max_17_18_daisi_d4 = frequency_all['17+18+daisi+dataset_4'].max()\n",
    "min_17_18_daisi_d4 = frequency_all['17+18+daisi+dataset_4'].min()\n",
    "IR_17_18_daisi_d4 = max_17_18_daisi_d4 / min_17_18_daisi_d4\n",
    "ln_IR_17_18_daisi_d4 = math.log(IR_17_18_daisi_d4,N_Balance)\n",
    "\n",
    "print(ln_IR_17_18_daisi_d4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a4SZsQEJfHTC"
   },
   "source": [
    "Load dataset_4 and CL model trained on 17,18,DAISI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1740666333792,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "hVDzQ2adfVGD"
   },
   "outputs": [],
   "source": [
    "class LrspDataset(Dataset):\n",
    "    def __init__(self, csv_file, data_type, patch_size=5):\n",
    "        self.patch_size = patch_size\n",
    "        tmp = pd.read_csv(csv_file)\n",
    "        self.data_frame = tmp[tmp['type']==data_type]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data_frame.iloc[idx]\n",
    "        file_name = str(sample['path'])\n",
    "        q = sample['q']\n",
    "        labels = torch.tensor(sample['labels'])\n",
    "\n",
    "        visual_feature_loc = '/' + os.path.join('content/drive/MyDrive/Colab Notebooks/research/multi-modality/dataset_4/vqa/img_features',(str(self.patch_size)+'x'+str(self.patch_size)),file_name+'.hdf5')\n",
    "        frame_data = h5py.File(visual_feature_loc, 'r')\n",
    "        visual_features = torch.from_numpy(frame_data['visual_features'][:])\n",
    "\n",
    "        t5_loss = torch.tensor(eval(sample['t5_loss']))\n",
    "\n",
    "        return file_name, visual_features, q, labels, t5_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5686,
     "status": "ok",
     "timestamp": 1740666339479,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "XzRV36cmfX5i",
    "outputId": "acefa0ff-a928-405d-cdf0-6add756b4b69"
   },
   "outputs": [],
   "source": [
    "train_dataset_lrsp = LrspDataset('/content/drive/MyDrive/Colab Notebooks/research/multi-modality/dataset_4/data.csv','train',patch_size=5)\n",
    "train_dataloader_lrsp = DataLoader(dataset=train_dataset_lrsp, batch_size=1, shuffle=True)\n",
    "len(train_dataset_lrsp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 145396,
     "status": "ok",
     "timestamp": 1740666484876,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "Zm1L0OGAg87a"
   },
   "outputs": [],
   "source": [
    "# old model 17\n",
    "checkpoint_17 = torch.load('/content/drive/MyDrive/Colab Notebooks/research/multi-modality/endovis17/Pretrain_t1.pth.tar')\n",
    "model_17 = checkpoint_17['model']\n",
    "\n",
    "# old model 18\n",
    "checkpoint_18 = torch.load('/content/drive/MyDrive/Colab Notebooks/research/multi-modality/endovis17/Pretrain_t2.pth.tar')\n",
    "model_18 = checkpoint_18['model']\n",
    "\n",
    "# old model daisi\n",
    "checkpoint_old = torch.load('/content/drive/MyDrive/Colab Notebooks/research/multi-modality/daisi_vqa_final/result/4980.pth.tar')\n",
    "model_old = checkpoint_old['model']\n",
    "\n",
    "# new model\n",
    "checkpoint_old = torch.load('/content/drive/MyDrive/Colab Notebooks/research/multi-modality/daisi_vqa_final/result/4980.pth.tar')\n",
    "model = checkpoint_old['model']\n",
    "\n",
    "optimizer = checkpoint_old['optimizer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1740666484879,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "4hgblJpJxxC7"
   },
   "outputs": [],
   "source": [
    "#change the last FC layer for new model (add the node for new classes)\n",
    "num_new_class = 4\n",
    "\n",
    "def kaiming_normal_init(m):\n",
    "\tif isinstance(m, nn.Conv2d):\n",
    "\t\tnn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "\telif isinstance(m, nn.Linear):\n",
    "\t\tnn.init.kaiming_normal_(m.weight, nonlinearity='sigmoid')\n",
    "\n",
    "# Old number of input/output channel of the last FC layer in old model\n",
    "in_features = model_18.classifier.in_features\n",
    "out_features = model_18.classifier.out_features\n",
    "\n",
    "# Old weight/bias of the last FC layer\n",
    "weight = model_18.classifier.weight.data\n",
    "bias = model_18.classifier.bias.data\n",
    "\n",
    "# New number of output channel of the last FC layer in new model\n",
    "new_out_features = num_new_class + out_features\n",
    "\n",
    "# Creat a new FC layer and initial it's weight/bias\n",
    "new_fc = nn.Linear(in_features, new_out_features)\n",
    "kaiming_normal_init(new_fc.weight)\n",
    "new_fc.weight.data[:out_features] = weight\n",
    "new_fc.bias.data[:out_features] = bias\n",
    "\n",
    "# Replace the old FC layer\n",
    "model_17.classifier = new_fc\n",
    "model_18.classifier = new_fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1740666484882,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "P70g_t5Ng8jj"
   },
   "outputs": [],
   "source": [
    "#change the last FC layer for new model (add the node for new classes)\n",
    "num_new_class = 2\n",
    "\n",
    "def kaiming_normal_init(m):\n",
    "\tif isinstance(m, nn.Conv2d):\n",
    "\t\tnn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "\telif isinstance(m, nn.Linear):\n",
    "\t\tnn.init.kaiming_normal_(m.weight, nonlinearity='sigmoid')\n",
    "\n",
    "# Old number of input/output channel of the last FC layer in old model\n",
    "in_features = model_old.classifier.in_features\n",
    "out_features = model_old.classifier.out_features\n",
    "\n",
    "# Old weight/bias of the last FC layer\n",
    "weight = model_old.classifier.weight.data\n",
    "bias = model_old.classifier.bias.data\n",
    "\n",
    "# New number of output channel of the last FC layer in new model\n",
    "new_out_features = num_new_class + out_features\n",
    "\n",
    "# Creat a new FC layer and initial it's weight/bias\n",
    "new_fc = nn.Linear(in_features, new_out_features)\n",
    "kaiming_normal_init(new_fc.weight)\n",
    "new_fc.weight.data[:out_features] = weight\n",
    "new_fc.bias.data[:out_features] = bias\n",
    "\n",
    "# Replace the old FC layer\n",
    "model.classifier = new_fc\n",
    "model_old.classifier = new_fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1740666484886,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "YcOlndC4id2L",
    "outputId": "8499d8e4-2d0a-48f5-84a3-e77a4f03566c"
   },
   "outputs": [],
   "source": [
    "# Move to GPU, if available\n",
    "model_17 = model_17.to(device)\n",
    "model_18 = model_18.to(device)\n",
    "model_old = model_old.to(device)\n",
    "model = model.to(device)\n",
    "print(final_args)\n",
    "pytorch_total_params = sum(p.numel() for p in model.parameters())\n",
    "print('model params: ', pytorch_total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1740666484887,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "ISQnZUoridwD"
   },
   "outputs": [],
   "source": [
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1740666484899,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "hu_IIY0didor"
   },
   "outputs": [],
   "source": [
    "args.checkpoint_dir = '/content/drive/MyDrive/Colab Notebooks/research/multi-modality/endovis18/result/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 0,
     "status": "ok",
     "timestamp": 1740666484904,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "UNhclY-ziddC"
   },
   "outputs": [],
   "source": [
    "# best model initialize\n",
    "start_epoch = 1\n",
    "best_epoch = [0]\n",
    "best_results = [0.0]\n",
    "epochs_since_improvement = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 0,
     "status": "ok",
     "timestamp": 1740666484904,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "C2vwwczuidTE"
   },
   "outputs": [],
   "source": [
    "out_features = model.classifier.out_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uwkF9q7Mioho"
   },
   "source": [
    "soft target 和大模型准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 0,
     "status": "ok",
     "timestamp": 1740666484905,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "d6gQHt39DfXO"
   },
   "outputs": [],
   "source": [
    "from pandas.core.frame import DataFrame\n",
    "from sklearn.metrics import accuracy_score\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 586288,
     "status": "ok",
     "timestamp": 1740667071193,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "eisitO6HivDD",
    "outputId": "2f1df379-1708-4737-cf5f-ce4b144991ec"
   },
   "outputs": [],
   "source": [
    "label = []\n",
    "label_soft_list = [] #软标签（旧模型所得）\n",
    "\n",
    "for i, (_, visual_features, q, labels, t5_loss) in enumerate(train_dataloader_lrsp,0):\n",
    "\n",
    "    label_number = labels.numpy()[0]\n",
    "    label += labels.tolist()\n",
    "\n",
    "    # prepare questions\n",
    "    questions = []\n",
    "    for question in q: questions.append(question)\n",
    "    inputs = tokenizer(questions, return_tensors=\"pt\", padding=\"max_length\", max_length=args.question_len)\n",
    "\n",
    "    # GPU / CPU\n",
    "    visual_features = visual_features.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    soft_target = model_17(inputs, visual_features)\n",
    "    output_class_ranks = torch.argsort(soft_target, dim=-1, descending=True)\n",
    "\n",
    "    label_soft = []\n",
    "    for j in range(len(output_class_ranks)):\n",
    "        label_soft.append(int(output_class_ranks[j][0]))\n",
    "    label_soft_list += label_soft\n",
    "\n",
    "c={\"label\" : label, \"label_soft_list\" : label_soft_list}\n",
    "data=DataFrame(c)\n",
    "acc_soft = []\n",
    "for i in range(22):\n",
    "    label_part = []\n",
    "    label_soft_part = []\n",
    "    for j in range(len(data)):\n",
    "        if data.at[j,'label'] == i:\n",
    "            label_part.append(data.at[j,'label'])\n",
    "            label_soft_part.append(data.at[j,'label_soft_list'])\n",
    "    acc_soft.append(accuracy_score(label_part, label_soft_part))\n",
    "acc_soft_17 = [0 if math.isnan(x) else x for x in acc_soft]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12646,
     "status": "ok",
     "timestamp": 1740667083841,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "Azl7UquaU8Uo",
    "outputId": "7d7d3cf7-6bc8-43fa-887f-c19078846340"
   },
   "outputs": [],
   "source": [
    "label = []\n",
    "label_soft_list = [] #软标签（旧模型所得）\n",
    "\n",
    "for i, (_, visual_features, q, labels, t5_loss) in enumerate(train_dataloader_lrsp,0):\n",
    "\n",
    "    label_number = labels.numpy()[0]\n",
    "    label += labels.tolist()\n",
    "\n",
    "    # prepare questions\n",
    "    questions = []\n",
    "    for question in q: questions.append(question)\n",
    "    inputs = tokenizer(questions, return_tensors=\"pt\", padding=\"max_length\", max_length=args.question_len)\n",
    "\n",
    "    # GPU / CPU\n",
    "    visual_features = visual_features.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    soft_target = model_18(inputs, visual_features)\n",
    "    output_class_ranks = torch.argsort(soft_target, dim=-1, descending=True)\n",
    "\n",
    "    label_soft = []\n",
    "    for j in range(len(output_class_ranks)):\n",
    "        label_soft.append(int(output_class_ranks[j][0]))\n",
    "    label_soft_list += label_soft\n",
    "\n",
    "c={\"label\" : label, \"label_soft_list\" : label_soft_list}\n",
    "data=DataFrame(c)\n",
    "acc_soft = []\n",
    "for i in range(22):\n",
    "    label_part = []\n",
    "    label_soft_part = []\n",
    "    for j in range(len(data)):\n",
    "        if data.at[j,'label'] == i:\n",
    "            label_part.append(data.at[j,'label'])\n",
    "            label_soft_part.append(data.at[j,'label_soft_list'])\n",
    "    acc_soft.append(accuracy_score(label_part, label_soft_part))\n",
    "acc_soft_18 = [0 if math.isnan(x) else x for x in acc_soft]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12736,
     "status": "ok",
     "timestamp": 1740667096578,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "NtT-03X4VDUz",
    "outputId": "5d77b966-74f5-45ef-b55f-5668b88a32cb"
   },
   "outputs": [],
   "source": [
    "label = []\n",
    "label_soft_list = [] #软标签（旧模型所得）\n",
    "\n",
    "for i, (_, visual_features, q, labels, t5_loss) in enumerate(train_dataloader_lrsp,0):\n",
    "\n",
    "    label_number = labels.numpy()[0]\n",
    "    label += labels.tolist()\n",
    "\n",
    "    # prepare questions\n",
    "    questions = []\n",
    "    for question in q: questions.append(question)\n",
    "    inputs = tokenizer(questions, return_tensors=\"pt\", padding=\"max_length\", max_length=args.question_len)\n",
    "\n",
    "    # GPU / CPU\n",
    "    visual_features = visual_features.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    soft_target = model_old(inputs, visual_features)\n",
    "    output_class_ranks = torch.argsort(soft_target, dim=-1, descending=True)\n",
    "\n",
    "    label_soft = []\n",
    "    for j in range(len(output_class_ranks)):\n",
    "        label_soft.append(int(output_class_ranks[j][0]))\n",
    "    label_soft_list += label_soft\n",
    "\n",
    "c={\"label\" : label, \"label_soft_list\" : label_soft_list}\n",
    "data=DataFrame(c)\n",
    "acc_soft = []\n",
    "for i in range(22):\n",
    "    label_part = []\n",
    "    label_soft_part = []\n",
    "    for j in range(len(data)):\n",
    "        if data.at[j,'label'] == i:\n",
    "            label_part.append(data.at[j,'label'])\n",
    "            label_soft_part.append(data.at[j,'label_soft_list'])\n",
    "    acc_soft.append(accuracy_score(label_part, label_soft_part))\n",
    "acc_soft_old = [0 if math.isnan(x) else x for x in acc_soft]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3179,
     "status": "ok",
     "timestamp": 1740667099758,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "eu5lvRiti29y"
   },
   "outputs": [],
   "source": [
    "label = []\n",
    "label_llm_list = []\n",
    "\n",
    "for i, (_, visual_features, q, labels, t5_loss) in enumerate(train_dataloader_lrsp,0):\n",
    "  label += labels.tolist()\n",
    "\n",
    "  t5_loss_list = []\n",
    "  for j in range(len(t5_loss)):\n",
    "    #tmp = str2list(t5_loss[j])\n",
    "    tmp = t5_loss[j][:22]\n",
    "    t5_loss_list.append(tmp)\n",
    "\n",
    "  check = np.reciprocal(t5_loss_list)\n",
    "  t5_loss_tensor = torch.tensor(check)\n",
    "  output_class_ranks = torch.argsort(t5_loss_tensor, dim=-1, descending=True)\n",
    "\n",
    "  label_llm = []\n",
    "  for j in range(len(output_class_ranks)):\n",
    "    label_llm.append(int(output_class_ranks[j][0]))\n",
    "\n",
    "  label_llm_list += label_llm\n",
    "\n",
    "c={\"label\" : label, \"label_llm_list\" : label_llm_list}\n",
    "data=DataFrame(c)\n",
    "\n",
    "acc_llm = []\n",
    "\n",
    "for i in range(22):\n",
    "  label_part = []\n",
    "  label_llm_part = []\n",
    "\n",
    "  for j in range(len(data)):\n",
    "    if data.at[j,'label'] == i:\n",
    "      label_part.append(data.at[j,'label'])\n",
    "      label_llm_part.append(data.at[j,'label_llm_list'])\n",
    "\n",
    "  if len(label_part) == 0:\n",
    "    acc_llm.append(0)\n",
    "  else:\n",
    "    acc_llm.append(accuracy_score(label_part, label_llm_part))\n",
    "\n",
    "acc_llm = [0 if math.isnan(x) else x for x in acc_llm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1740667099784,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "owQO074p8z6z",
    "outputId": "151ff8d2-7b4e-4bb5-b207-25512f13829e"
   },
   "outputs": [],
   "source": [
    "acc_soft_17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1740667099786,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "DxNPnap2VNwt",
    "outputId": "8b8b9299-68ce-409a-f119-b096d9fd46dd"
   },
   "outputs": [],
   "source": [
    "acc_soft_18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1740667099788,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "AMN7DBwuVPbt",
    "outputId": "d356a917-fc96-4a07-f2d4-5ff7a1dbe571"
   },
   "outputs": [],
   "source": [
    "acc_soft_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1740667099790,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "rnkO8UwuVMxk"
   },
   "outputs": [],
   "source": [
    "acc_soft = [(x + y + z) / 3 for x, y, z in zip(acc_soft_17, acc_soft_18, acc_soft_old)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1740667099792,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "nMHNmSU2dyJq",
    "outputId": "7c670258-3e41-4380-978e-2c8de754b84a"
   },
   "outputs": [],
   "source": [
    "acc_soft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bmDsgP4Sy2j5"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1740667099807,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "YHKzeLy-85Cb",
    "outputId": "93725741-f9ed-47a0-d4a5-e278cfb8041c"
   },
   "outputs": [],
   "source": [
    "acc_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1740667099809,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "I6fgASYVi9Pb"
   },
   "outputs": [],
   "source": [
    "#To reduce the time of assessing the old model, we only caculate once in the first time.\n",
    "# acc_soft_17=[0,0.9875,0.010638297872340425,0.0,0.0,0.0,0,0.0,0,0,0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0]\n",
    "# acc_soft_18=[0,0.9875,0.0,0.0,0.0,0.0,0,0.0,0,0,0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0]\n",
    "# acc_soft_old=[0,0.9375,0.0,0.0,0.0,0.0,0,0.0,0,0,0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0]\n",
    "# acc_soft=[0.0,0.9708333333333333,0.0035460992907801418,0.0,0.0,0.0,0,0.0,0,0,0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0]\n",
    "# acc_llm=[0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0,0,0,0.7647058823529411,0.6282051282051282,1.0,0.0]\n",
    "\n",
    "from pandas.core.frame import DataFrame\n",
    "from sklearn.metrics import accuracy_score\n",
    "import math\n",
    "\n",
    "c={\"acc_soft\" : acc_soft, \"acc_llm\" : acc_llm}\n",
    "\n",
    "weight_data_17_18_daisi=DataFrame(c)\n",
    "\n",
    "\n",
    "for i in range(len(weight_data_17_18_daisi)):\n",
    "  if weight_data_17_18_daisi.at[i,'acc_soft'] + weight_data_17_18_daisi.at[i,'acc_llm'] == 0:\n",
    "    weight_data_17_18_daisi.at[i,'DS_soft'] = 0.5*(1 - hard_label_weight)\n",
    "    weight_data_17_18_daisi.at[i,'DS_llm'] = 0.5*(1 - hard_label_weight)\n",
    "  else:\n",
    "    weight_data_17_18_daisi.at[i,'DS_soft'] = (1-hard_label_weight) * weight_data_17_18_daisi.at[i,'acc_soft'] / (weight_data_17_18_daisi.at[i,'acc_soft'] + weight_data_17_18_daisi.at[i,'acc_llm'])\n",
    "    weight_data_17_18_daisi.at[i,'DS_llm'] = (1-hard_label_weight) * weight_data_17_18_daisi.at[i,'acc_llm'] / (weight_data_17_18_daisi.at[i,'acc_soft'] + weight_data_17_18_daisi.at[i,'acc_llm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 0,
     "status": "ok",
     "timestamp": 1740667099810,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "QzZvYsmzjEkN"
   },
   "outputs": [],
   "source": [
    "#weight processing\n",
    "weight_data_17_18_daisi['DI_soft']=(1-hard_label_weight) * (1 / (1 + ln_IR_17_18_daisi_d4))\n",
    "weight_data_17_18_daisi['DI_llm'] = (1-hard_label_weight) * ((ln_IR_17_18_daisi_d4) / (1 + ln_IR_17_18_daisi_d4))\n",
    "weight_data_17_18_daisi['weight_true_label']=hard_label_weight\n",
    "weight_data_17_18_daisi['weight_soft'] = DS_weight * weight_data_17_18_daisi['DS_soft'] + DI_weight * weight_data_17_18_daisi['DI_soft']\n",
    "weight_data_17_18_daisi['weight_llm'] = DS_weight * weight_data_17_18_daisi['DS_llm'] + DI_weight * weight_data_17_18_daisi['DI_llm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1740667099813,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "4q8aJFUljEdj",
    "outputId": "7427a5c4-37db-4c74-e45c-ddd86fe11dbe"
   },
   "outputs": [],
   "source": [
    "acc_weight = weight_data_17_18_daisi[['weight_true_label','weight_soft','weight_llm']]\n",
    "acc_weight.weight_data_17_18_daisi = ['weight_true_label','weight_soft','weight_llm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 739
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1740667099834,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "8rZA1ZVCxT1H",
    "outputId": "f4077d3e-13b1-4e8d-d567-b00d2a9d4d72"
   },
   "outputs": [],
   "source": [
    "len(weight_data_17_18_daisi)\n",
    "acc_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1740667099835,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "Fsikge2OhwUT"
   },
   "outputs": [],
   "source": [
    "# d-daisi\n",
    "class DaisiVQADataset_old(Dataset):\n",
    "    def __init__(self, csv_file, data_type, patch_size=5):\n",
    "        self.patch_size = patch_size\n",
    "        tmp = pd.read_csv(csv_file)\n",
    "        self.data_frame = tmp[tmp['type']==data_type]\n",
    "        unique_files = len(self.data_frame['path'].unique())\n",
    "        total_questions = len(self.data_frame)\n",
    "        print(f\"Total files: {unique_files} | Total questions: {total_questions}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data_frame.iloc[idx]\n",
    "        q = sample['q']\n",
    "        labels = torch.tensor(sample['labels'])\n",
    "        file_name = str(sample['path'])\n",
    "\n",
    "        visual_feature_loc = '/' + os.path.join('content/drive/MyDrive/Colab Notebooks/research/multi-modality/daisi_vqa_final/data/',file_name,'vqa/img_features',(str(self.patch_size)+'x'+str(self.patch_size)),file_name+'.hdf5')\n",
    "        frame_data = h5py.File(visual_feature_loc, 'r')\n",
    "        visual_features = torch.from_numpy(frame_data['visual_features'][:])\n",
    "\n",
    "        t5_loss = torch.tensor(eval(sample['t5_loss']))\n",
    "\n",
    "        return file_name, visual_features, q, labels, t5_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 252284,
     "status": "ok",
     "timestamp": 1740667352119,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "EMGypmxy0TuA",
    "outputId": "e656d79b-53aa-43df-d152-1bc5099b4352"
   },
   "outputs": [],
   "source": [
    "val_dataset_d4 = LrspDataset('/content/drive/MyDrive/Colab Notebooks/research/multi-modality/dataset_4/data.csv','val',patch_size=5)\n",
    "val_dataloader_d4 = DataLoader(dataset=val_dataset_d4, batch_size=1, shuffle=False)\n",
    "\n",
    "\n",
    "val_dataset_17 = EndoVis17VQAClassification([8],'/content/drive/MyDrive/Colab Notebooks/research/multi-modality/endovis17/seq_',\n",
    "                        '/vqa/*.txt', patch_size = 5)\n",
    "val_dataloader_17 = DataLoader(dataset=val_dataset_17, batch_size= 64, shuffle=False)\n",
    "\n",
    "\n",
    "val_dataset_18 = EndoVis18VQAClassification([1,5,16],'/content/drive/MyDrive/Colab Notebooks/research/multi-modality/endovis18/seq_',\n",
    "                          '/vqa/Classification_t5_loss/*.txt', patch_size = 5)\n",
    "val_dataloader_18 = DataLoader(dataset=val_dataset_18, batch_size= 64, shuffle=False)\n",
    "\n",
    "val_dataset_daisi = DaisiVQADataset_old('/content/drive/MyDrive/Colab Notebooks/research/multi-modality/daisi_vqa_final/daisi_data.csv',\n",
    "                                        'val',patch_size=5)\n",
    "val_dataloader_daisi = DataLoader(dataset=val_dataset_daisi, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1740667352122,
     "user": {
      "displayName": "Zhan Yue",
      "userId": "08639667611526145892"
     },
     "user_tz": -480
    },
    "id": "_AOQa692DBkx"
   },
   "outputs": [],
   "source": [
    "# len(val_dataset_d4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QIKNk_2xjEM0",
    "outputId": "8e5c98b9-b8b1-4721-caad-1c323926d4ea"
   },
   "outputs": [],
   "source": [
    "for epoch in range(start_epoch, epoch_num): # train only a few epoch to reduce training time\n",
    "\n",
    "  if epochs_since_improvement > 0 and epochs_since_improvement % 5 == 0:\n",
    "    adjust_learning_rate(optimizer, 0.8)\n",
    "\n",
    "  # train\n",
    "  train_acc = train_d4(args, train_dataloader=train_dataloader_lrsp, model = model, criterion=criterion, optimizer=optimizer, epoch=epoch, tokenizer = tokenizer, device = device)\n",
    "\n",
    "  # validation\n",
    "  #test 17\n",
    "  test_acc_17, test_c_acc, test_precision, test_recall, test_fscore_17 = validate_17(args,val_loader=val_dataloader_17, model = model, criterion=criterion, epoch=epoch, tokenizer = tokenizer, device = device)\n",
    "\n",
    "  #test 18\n",
    "  test_acc_18, test_c_acc, test_precision, test_recall, test_fscore_18 = validate_18_d3_d4(args,val_loader=val_dataloader_18, model = model, criterion=criterion, epoch=epoch, tokenizer = tokenizer, device = device)\n",
    "\n",
    "  #test daisi\n",
    "  test_acc_daisi, test_c_acc, test_precision, test_recall, test_fscore_daisi = validate_18_d3_d4(args,val_loader=val_dataloader_daisi, model = model, criterion=criterion, epoch=epoch, tokenizer = tokenizer, device = device)\n",
    "\n",
    "  test_acc, test_c_acc, test_precision, test_recall, test_fscore_d4 = validate_18_d3_d4(args, val_loader=val_dataloader_d4, model = model, criterion=criterion, epoch=epoch, tokenizer = tokenizer, device = device)\n",
    "\n",
    "  test_acc_d4=test_acc\n",
    "\n",
    "  av_acc = (test_acc_d4+test_acc_17+test_acc_18+test_acc_daisi)/4\n",
    "  av_fscore = (test_fscore_d4+test_fscore_17+test_fscore_18+test_fscore_daisi)/4\n",
    "  print('epoch: %d | Average acc: %.6f' %(epoch, av_acc))\n",
    "  print('epoch: %d | Average fscore: %.6f' %(epoch, av_fscore))\n",
    "\n",
    "  if av_acc >= best_results[0]:\n",
    "    epochs_since_improvement = 0\n",
    "\n",
    "    best_results[0] = av_acc\n",
    "    best_epoch[0] = epoch\n",
    "    save_clf_checkpoint(args.checkpoint_dir, epoch, epochs_since_improvement, model, optimizer, best_results[0], final_args)\n",
    "\n",
    "  else:\n",
    "    epochs_since_improvement += 1\n",
    "\n",
    "  if train_acc >= 1.0: break"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPk5nQxqQVemx1R6PPg3A0A",
   "gpuType": "T4",
   "machine_shape": "hm",
   "mount_file_id": "1JgFydiRsPli5HMjb8bMdU1zZZZr7ezhe",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
